{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "# ğŸ¨ Vanilla ComfyUI Colab\n",
        "\n",
        "A clean, minimal setup for running ComfyUI in Google Colab.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install-comfyui"
      },
      "source": [
        "## ğŸ“¦ Install ComfyUI & Dependencies\n",
        "\n",
        "This will install ComfyUI, all required dependencies, and ComfyUI Manager."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3XhJ3y1_N9C",
        "outputId": "b7bc14a8-8ae7-4543-aaab-b37b584ce8dd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "install-cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01a1001-22b3-4e57-c8e6-c22ae637bab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ Cloning ComfyUI repository...\n",
            "Cloning into '/content/ComfyUI'...\n",
            "remote: Enumerating objects: 32335, done.\u001b[K\n",
            "remote: Counting objects: 100% (330/330), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 32335 (delta 214), reused 157 (delta 157), pack-reused 32005 (from 3)\u001b[K\n",
            "Receiving objects: 100% (32335/32335), 71.86 MiB | 16.53 MiB/s, done.\n",
            "Resolving deltas: 100% (21937/21937), done.\n",
            "âœ… ComfyUI cloned successfully\n",
            "\n",
            "/content/ComfyUI\n",
            "ğŸ”„ Updating ComfyUI...\n",
            "Already up to date.\n",
            "âœ… ComfyUI updated\n",
            "\n",
            "ğŸ“¦ Installing dependencies...\n",
            "\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâš¡ Installing PyTorch with CUDA 12.1...\n",
            "ğŸ“š Installing core dependencies...\n",
            "ğŸ¤— Installing transformers and huggingface-hub...\n",
            "ğŸš€ Installing optional packages...\n",
            "âœ… All dependencies installed successfully!\n",
            "\n",
            "ğŸ“¥ Installing ComfyUI Manager...\n",
            "Cloning into '/content/ComfyUI/custom_nodes/ComfyUI-Manager'...\n",
            "remote: Enumerating objects: 28475, done.\u001b[K\n",
            "remote: Counting objects: 100% (897/897), done.\u001b[K\n",
            "remote: Compressing objects: 100% (405/405), done.\u001b[K\n",
            "remote: Total 28475 (delta 735), reused 502 (delta 492), pack-reused 27578 (from 3)\u001b[K\n",
            "Receiving objects: 100% (28475/28475), 128.39 MiB | 14.79 MiB/s, done.\n",
            "Resolving deltas: 100% (21119/21119), done.\n",
            "âœ… ComfyUI Manager installed\n",
            "\n",
            "ğŸ“‹ Installed versions:\n",
            "\n",
            "  âœ… torch: 2.9.0+cu128\n",
            "  âœ… transformers: 4.56.2\n",
            "  âœ… huggingface-hub: 0.36.2\n",
            "  âœ… tokenizers: 0.22.2\n",
            "  âœ… safetensors: 0.7.0\n",
            "\n",
            "==================================================\n",
            "ğŸ‰ Installation complete!\n",
            "==================================================\n",
            "\n",
            "âœ… You can now run the Launch cell below!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "WORKSPACE = \"/content/ComfyUI\"\n",
        "\n",
        "# ========================================\n",
        "# 1. Clone ComfyUI\n",
        "# ========================================\n",
        "if not os.path.exists(WORKSPACE):\n",
        "    print(\"ğŸ“¥ Cloning ComfyUI repository...\")\n",
        "    !git clone https://github.com/comfyanonymous/ComfyUI {WORKSPACE}\n",
        "    print(\"âœ… ComfyUI cloned successfully\\n\")\n",
        "else:\n",
        "    print(\"âœ… ComfyUI directory already exists\\n\")\n",
        "\n",
        "# Change to ComfyUI directory\n",
        "%cd {WORKSPACE}\n",
        "\n",
        "# Update ComfyUI\n",
        "print(\"ğŸ”„ Updating ComfyUI...\")\n",
        "!git pull\n",
        "print(\"âœ… ComfyUI updated\\n\")\n",
        "\n",
        "# ========================================\n",
        "# 2. Install Dependencies\n",
        "# ========================================\n",
        "print(\"ğŸ“¦ Installing dependencies...\\n\")\n",
        "\n",
        "# Upgrade pip\n",
        "!pip install --upgrade pip -q\n",
        "\n",
        "# Install PyTorch with CUDA support\n",
        "print(\"âš¡ Installing PyTorch with CUDA 12.1...\")\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 -q\n",
        "\n",
        "# Install core dependencies\n",
        "print(\"ğŸ“š Installing core dependencies...\")\n",
        "!pip install -q \\\n",
        "    accelerate \\\n",
        "    einops \\\n",
        "    \"safetensors>=0.4.2\" \\\n",
        "    aiohttp \\\n",
        "    pyyaml \\\n",
        "    Pillow \\\n",
        "    scipy \\\n",
        "    tqdm \\\n",
        "    psutil \\\n",
        "    \"tokenizers>=0.13.3\" \\\n",
        "    sentencepiece \\\n",
        "    soundfile \\\n",
        "    \"kornia>=0.7.1\" \\\n",
        "    spandrel \\\n",
        "    torchsde \\\n",
        "    comfy_aimdo \\\n",
        "    av \\\n",
        "    comfy-kitchen \\\n",
        "    comfyui-workflow-templates \\\n",
        "    comfyui-embedded-docs\n",
        "\n",
        "# Install transformers and huggingface-hub with compatible versions\n",
        "print(\"ğŸ¤— Installing transformers and huggingface-hub...\")\n",
        "!pip install -q \\\n",
        "    \"transformers>=4.45.0,<4.57.0\" \\\n",
        "    \"huggingface-hub>=0.23.0,<1.0\"\n",
        "\n",
        "# Install optional speedup packages\n",
        "print(\"ğŸš€ Installing optional packages...\")\n",
        "!pip install -q hf_transfer\n",
        "\n",
        "print(\"âœ… All dependencies installed successfully!\\n\")\n",
        "\n",
        "# ========================================\n",
        "# 3. Install ComfyUI Manager\n",
        "# ========================================\n",
        "manager_path = f\"{WORKSPACE}/custom_nodes/ComfyUI-Manager\"\n",
        "\n",
        "if not os.path.exists(manager_path):\n",
        "    print(\"ğŸ“¥ Installing ComfyUI Manager...\")\n",
        "    !git clone https://github.com/ltdrdata/ComfyUI-Manager {manager_path}\n",
        "    print(\"âœ… ComfyUI Manager installed\\n\")\n",
        "else:\n",
        "    print(\"ğŸ”„ Updating ComfyUI Manager...\")\n",
        "    !cd {manager_path} && git pull\n",
        "    print(\"âœ… ComfyUI Manager updated\\n\")\n",
        "\n",
        "# ========================================\n",
        "# 4. Verify Installation\n",
        "# ========================================\n",
        "import importlib.metadata as metadata\n",
        "\n",
        "print(\"ğŸ“‹ Installed versions:\\n\")\n",
        "\n",
        "packages = [\n",
        "    \"torch\",\n",
        "    \"transformers\",\n",
        "    \"huggingface-hub\",\n",
        "    \"tokenizers\",\n",
        "    \"safetensors\"\n",
        "]\n",
        "\n",
        "for pkg in packages:\n",
        "    try:\n",
        "        version = metadata.version(pkg)\n",
        "        print(f\"  âœ… {pkg}: {version}\")\n",
        "    except:\n",
        "        print(f\"  âŒ {pkg}: not found\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸ‰ Installation complete!\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nâœ… You can now run the Launch cell below!\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# ğŸ“©Install Custom Models and Nodes"
      ],
      "metadata": {
        "id": "EwRf3DiJK3vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Install Models & Custom Nodes\n",
        "# ========================================\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"ğŸ“¦ Installing Models & Custom Nodes\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "MODELS_DIR = \"/content/ComfyUI/models\"\n",
        "CUSTOM_NODES_DIR = \"/content/ComfyUI/custom_nodes\"\n",
        "\n",
        "# Enable fast HuggingFace downloads\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "\n",
        "# ========================================\n",
        "# âš™ï¸ CONFIGURATION - Just add links here\n",
        "# ========================================\n",
        "\n",
        "# Custom Nodes - GitHub repository URLs\n",
        "CUSTOM_NODES = [\n",
        "    \"https://github.com/ainvfx/ComfyUI-SeedVR2_VideoUpscaler.git\",\n",
        "    \"https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git\",\n",
        "    \"https://github.com/rgthree/rgthree-comfy.git\",\n",
        "    \"https://github.com/lihaoyun6/ComfyUI-FlashVSR_Ultra_Fast.git\",\n",
        "    \"https://github.com/kijai/ComfyUI-GIMM-VFI\",\n",
        "    \"https://github.com/chflame163/ComfyUI_LayerStyle.git\",\n",
        "]\n",
        "\n",
        "# Models - HuggingFace URLs or direct download links\n",
        "MODELS = [\n",
        "    # SeedVR2 DiT â†’ needs its own folder, not checkpoints\n",
        "    \"https://huggingface.co/ainvfx/SeedVR2/resolve/main/seedvr2_ema_3b-Q8_0.gguf\",\n",
        "    \"https://huggingface.co/ainvfx/SeedVR2/resolve/main/ema_vae_fp16.safetensors\",\n",
        "    # GIMM-VFI\n",
        "    \"https://huggingface.co/FuouM/GIMM-VFI/resolve/main/gimmvfi_r_arb_lpips_fp32.safetensors\",\n",
        "]\n",
        "\n",
        "# ========================================\n",
        "# Auto-detect and install\n",
        "# ========================================\n",
        "\n",
        "# Install Custom Nodes\n",
        "if CUSTOM_NODES:\n",
        "    print(\"ğŸ”§ Installing Custom Nodes...\\n\")\n",
        "    for repo_url in CUSTOM_NODES:\n",
        "        node_name = repo_url.split('/')[-1].replace('.git', '')\n",
        "        node_path = f\"{CUSTOM_NODES_DIR}/{node_name}\"\n",
        "\n",
        "        if not os.path.exists(node_path):\n",
        "            print(f\"ğŸ“¥ {node_name}...\")\n",
        "            !git clone -q {repo_url} {node_path}\n",
        "            print(f\"âœ… {node_name} installed\")\n",
        "        else:\n",
        "            print(f\"â­ï¸  {node_name} (already exists)\")\n",
        "\n",
        "    print(\"\\nğŸ“š Installing dependencies...\")\n",
        "    !find /content/ComfyUI/custom_nodes -name \"requirements.txt\" -exec pip install -q -r {} \\;\n",
        "    print(\"âœ… Dependencies installed\\n\")\n",
        "\n",
        "# Download Models\n",
        "if MODELS:\n",
        "    from huggingface_hub import hf_hub_download\n",
        "    print(\"ğŸ¨ Downloading Models (with fast HF transfer)...\\n\")\n",
        "\n",
        "    for url in MODELS:\n",
        "        filename = url.split('/')[-1].split('?')[0]\n",
        "\n",
        "        # Auto-detect folder based on file extension/name\n",
        "        if \"upscale\" in filename.lower() or filename.endswith('.pth'):\n",
        "            model_dir = f\"{MODELS_DIR}/upscale_models\"\n",
        "        elif \"controlnet\" in filename.lower():\n",
        "            model_dir = f\"{MODELS_DIR}/controlnet\"\n",
        "        elif \"yolo\" in filename.lower() or \"face\" in filename.lower():\n",
        "            model_dir = f\"{MODELS_DIR}/ultralytics/bbox\"\n",
        "        else:\n",
        "            model_dir = f\"{MODELS_DIR}/checkpoints\"\n",
        "\n",
        "        os.makedirs(model_dir, exist_ok=True)\n",
        "        filepath = f\"{model_dir}/{filename}\"\n",
        "\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"ğŸ“¥ {filename} â†’ {model_dir.split('/')[-1]}/\")\n",
        "\n",
        "            if \"huggingface.co\" in url:\n",
        "                parts = url.split(\"huggingface.co/\")[1].split(\"/\")\n",
        "                repo_id = f\"{parts[0]}/{parts[1]}\"\n",
        "                file_path = \"/\".join(parts[4:])\n",
        "\n",
        "                try:\n",
        "                    hf_hub_download(\n",
        "                        repo_id=repo_id,\n",
        "                        filename=file_path,\n",
        "                        local_dir=model_dir,\n",
        "                        local_dir_use_symlinks=False\n",
        "                    )\n",
        "                    print(f\"âœ… Downloaded\\n\")\n",
        "                except:\n",
        "                    !wget -q --show-progress -c \"{url}\" -O {filepath}\n",
        "            else:\n",
        "                !wget -q --show-progress -c \"{url}\" -O {filepath}\n",
        "        else:\n",
        "            print(f\"â­ï¸  {filename} (already exists)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"âœ… Installation Complete!\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrsuMAQqK2gb",
        "outputId": "89c2602e-0888-4d97-8d69-b08f98203d58"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "ğŸ“¦ Installing Models & Custom Nodes\n",
            "==================================================\n",
            "ğŸ”§ Installing Custom Nodes...\n",
            "\n",
            "ğŸ“¥ ComfyUI-SeedVR2_VideoUpscaler...\n",
            "âœ… ComfyUI-SeedVR2_VideoUpscaler installed\n",
            "ğŸ“¥ ComfyUI-VideoHelperSuite...\n",
            "âœ… ComfyUI-VideoHelperSuite installed\n",
            "ğŸ“¥ rgthree-comfy...\n",
            "âœ… rgthree-comfy installed\n",
            "ğŸ“¥ ComfyUI-FlashVSR_Ultra_Fast...\n",
            "âœ… ComfyUI-FlashVSR_Ultra_Fast installed\n",
            "ğŸ“¥ ComfyUI-GIMM-VFI...\n",
            "âœ… ComfyUI-GIMM-VFI installed\n",
            "ğŸ“¥ ComfyUI_LayerStyle...\n",
            "âœ… ComfyUI_LayerStyle installed\n",
            "\n",
            "ğŸ“š Installing dependencies...\n",
            "âœ… Dependencies installed\n",
            "\n",
            "ğŸ¨ Downloading Models (with fast HF transfer)...\n",
            "\n",
            "ğŸ“¥ seedvr2_ema_3b-Q8_0.gguf â†’ checkpoints/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:986: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ ema_vae_fp16.safetensors â†’ checkpoints/\n",
            "ğŸ“¥ gimmvfi_r_arb_lpips_fp32.safetensors â†’ checkpoints/\n",
            "\n",
            "==================================================\n",
            "âœ… Installation Complete!\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fix blocks"
      ],
      "metadata": {
        "id": "YfeC4ECDyc5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rotary_embedding_torch blend_modes -q"
      ],
      "metadata": {
        "id": "EpqMM3YEyB4o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "\n",
        "COMFYUI = \"/content/ComfyUI/models\"\n",
        "\n",
        "# SeedVR2 models need to go into their own subfolder\n",
        "os.makedirs(f\"{COMFYUI}/SeedVR2\", exist_ok=True)\n",
        "for f in [\"seedvr2_ema_3b-Q8_0.gguf\", \"ema_vae_fp16.safetensors\"]:\n",
        "    src = f\"{COMFYUI}/checkpoints/{f}\"\n",
        "    dst = f\"{COMFYUI}/SeedVR2/{f}\"\n",
        "    if os.path.exists(src) and not os.path.exists(dst):\n",
        "        shutil.move(src, dst)\n",
        "        print(f\"âœ… Moved {f} â†’ SeedVR2/\")\n",
        "\n",
        "# GIMM-VFI model\n",
        "os.makedirs(f\"{COMFYUI}/GIMM-VFI\", exist_ok=True)\n",
        "for f in [\"gimmvfi_r_arb_lpips_fp32.safetensors\"]:\n",
        "    src = f\"{COMFYUI}/checkpoints/{f}\"\n",
        "    dst = f\"{COMFYUI}/GIMM-VFI/{f}\"\n",
        "    if os.path.exists(src) and not os.path.exists(dst):\n",
        "        shutil.move(src, dst)\n",
        "        print(f\"âœ… Moved {f} â†’ GIMM-VFI/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RQ-COQZybxx",
        "outputId": "a4fd33de-3d43-4bc0-adbc-cd07d3e04465"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Moved seedvr2_ema_3b-Q8_0.gguf â†’ SeedVR2/\n",
            "âœ… Moved ema_vae_fp16.safetensors â†’ SeedVR2/\n",
            "âœ… Moved gimmvfi_r_arb_lpips_fp32.safetensors â†’ GIMM-VFI/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "batch-runner-header"
      },
      "source": [
        "---\n",
        "\n",
        "# âš™ï¸ Batch Workflow Runner\n",
        "\n",
        "Watches an **input** folder, runs any file through a ComfyUI workflow automatically, saves outputs, and moves processed files.\n",
        "\n",
        "**Folder structure** (all created automatically):\n",
        "```\n",
        "MAIN_FOLDER/\n",
        "  â”œâ”€â”€ input/        â† drop files here\n",
        "  â”œâ”€â”€ processed/    â† files moved here after running\n",
        "  â”œâ”€â”€ output/       â† ComfyUI outputs saved here\n",
        "  â””â”€â”€ workflow.json â† your exported ComfyUI workflow (API format)\n",
        "```\n",
        "\n",
        "> **How to export workflow in API format:** In ComfyUI â†’ Settings â†’ Enable Dev Mode â†’ \"Save (API Format)\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batch-runner-cell",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bffa6f67-02d7-4666-ceca-67c1cff525b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ğŸ—‚ï¸  ComfyUI Batch Workflow Runner\n",
            "============================================================\n",
            "  Main folder   : /content/drive/Shareddrives/Figuro/video-upscale\n",
            "  Input         : /content/drive/Shareddrives/Figuro/video-upscale/input\n",
            "  Processed     : /content/drive/Shareddrives/Figuro/video-upscale/processed\n",
            "  Output        : /content/drive/Shareddrives/Figuro/video-upscale/output\n",
            "  Workflow      : /content/drive/Shareddrives/Figuro/video-upscale/FaboroHacks_HD_video_upscale_V1_api.json\n",
            "  Input node ID : 29  (field auto-detected at runtime)\n",
            "  Poll interval : 10s\n",
            "  Extensions    : bmp, gif, jpeg, jpg, mp4, png, tiff, webp\n",
            "============================================================\n",
            "/content/ComfyUI\n",
            "â³ Waiting for ComfyUI to start...\n",
            "ğŸš€ Starting ComfyUI + Batch Watcher...\n",
            "â³ Please wait for the interface to load below...\n",
            "\n",
            "..[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2026-02-13 12:38:04.578\n",
            "** Platform: Linux\n",
            "** Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/ComfyUI\n",
            "** User directory: /content/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/ComfyUI/user/__manager/config.ini\n",
            "** Log path: /content/ComfyUI/user/comfyui.log\n",
            "...[ComfyUI-Manager] 'comfyui-frontend-package' dependency were fixed\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   6.3 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "..Checkpoint files will always be loaded safely.\n",
            "...WARNING: You need pytorch with cu130 or higher to use optimized CUDA operations.\n",
            "Found comfy_kitchen backend eager: {'available': True, 'disabled': False, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8', 'scaled_mm_nvfp4']}\n",
            "Found comfy_kitchen backend triton: {'available': True, 'disabled': True, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8']}\n",
            "Found comfy_kitchen backend cuda: {'available': True, 'disabled': True, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8', 'scaled_mm_nvfp4']}\n",
            "Total VRAM 22563 MB, total RAM 54229 MB\n",
            "pytorch version: 2.9.0+cu128\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 NVIDIA L4 : cudaMallocAsync\n",
            "Using async weight offloading with 2 streams\n",
            "Enabled pinned memory 51517.0\n",
            "working around nvidia conv3d memory bug.\n",
            ".Using pytorch attention\n",
            ".Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "ComfyUI version: 0.13.0\n",
            "ComfyUI frontend version: 1.38.13\n",
            "[Prompt Server] web root: /usr/local/lib/python3.12/dist-packages/comfyui_frontend_package/static\n",
            ".### Loading: ComfyUI-Manager (V3.39.2)\n",
            "[ComfyUI-Manager] network_mode: public\n",
            "[ComfyUI-Manager] ComfyUI per-queue preview override detected (PR #11261). Manager's preview method feature is disabled. Use ComfyUI's --preview-method CLI option or 'Settings > Execution > Live preview method'.\n",
            "### ComfyUI Version: v0.13.0-19-ge03fe8b5 | Released on '2026-02-12'\n",
            "âš ï¸  SeedVR2 optimizations check: SageAttention âŒ | Flash Attention âŒ | Triton âœ…\n",
            "ğŸ’¡ Optional: pip install sageattention flash-attn\n",
            "ğŸ”§ Conv3d workaround active: PyTorch 2.9.0, cuDNN 91002 (fixing VAE 3x memory bug)\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "ğŸ“Š Initial CUDA memory: 21.78GB free / 22.03GB total\n",
            "..2026-02-13 12:38:30.150810: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-02-13 12:38:30.167900: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770986310.189442    7623 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770986310.196996    7623 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770986310.216983    7623 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770986310.217021    7623 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770986310.217026    7623 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770986310.217030    7623 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-13 12:38:30.222043: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "FETCH ComfyRegistry Data: 5/125\n",
            "...FETCH ComfyRegistry Data: 10/125\n",
            "NumExpr defaulting to 12 threads.\n",
            ".Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "/content/ComfyUI/custom_nodes/ComfyUI-GIMM-VFI/nodes.py:52: SyntaxWarning: invalid escape sequence '\\m'\n",
            "  DESCRIPTION = \"Downloads and loads GIMM-VFI model from folder 'ComfyUI\\models\\interpolation\\gimm-vfi'\"\n",
            ".FETCH ComfyRegistry Data: 15/125\n",
            "..FETCH ComfyRegistry Data: 20/125\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "\n",
            "\u001b[92m[rgthree-comfy] Loaded 48 epic nodes. ğŸ‰\u001b[0m\n",
            "\n",
            "\u001b[33m[rgthree-comfy] ComfyUI's new Node 2.0 rendering may be incompatible with some rgthree-comfy nodes and features, breaking some rendering as well as losing the ability to access a node's properties (a vital part of many nodes). It also appears to run MUCH more slowly spiking CPU usage and causing jankiness and unresponsiveness, especially with large workflows. Personally I am not planning to use the new Nodes 2.0 and, unfortunately, am not able to invest the time to investigate and overhaul rgthree-comfy where needed. If you have issues when Nodes 2.0 is enabled, I'd urge you to switch it off as well and join me in hoping ComfyUI is not planning to deprecate the existing, stable canvas rendering all together.\n",
            "\u001b[0m\n",
            ".\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   0.1 seconds: /content/ComfyUI/custom_nodes/ComfyUI-FlashVSR_Ultra_Fast\n",
            "   0.1 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "   0.3 seconds: /content/ComfyUI/custom_nodes/ComfyUI_LayerStyle\n",
            "   0.8 seconds: /content/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite\n",
            "   5.9 seconds: /content/ComfyUI/custom_nodes/ComfyUI-GIMM-VFI\n",
            "  12.2 seconds: /content/ComfyUI/custom_nodes/ComfyUI-SeedVR2_VideoUpscaler\n",
            "\n",
            "Context impl SQLiteImpl.\n",
            "Will assume non-transactional DDL.\n",
            "Context impl SQLiteImpl.\n",
            "Will assume non-transactional DDL.\n",
            "Running upgrade  -> 0001_assets, Initial assets schema\n",
            "Revision ID: 0001_assets\n",
            "Revises: None\n",
            "Create Date: 2025-12-10 00:00:00\n",
            "Database upgraded from None to 0001_assets\n",
            "Assets scan(roots=['models']) completed in 0.053s (created=11, skipped_existing=0, orphans_pruned=0, total_seen=11)\n",
            "\n",
            "ğŸŒ ComfyUI is ready! Opening in iframe below...\n",
            "ğŸ’¡ Tip: Click the link to open in a new window\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8188, \"/\", \"100%\", 900, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mWarning: This function may stop working due to changes in browser security.\n",
            "Try `serve_kernel_port_as_iframe` instead. \u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8188, \"/\", \"https://localhost:8188/\", window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " âœ… Ready!\n",
            "\n",
            "âœ… Workflow loaded  : /content/drive/Shareddrives/Figuro/video-upscale/FaboroHacks_HD_video_upscale_V1_api.json\n",
            "   Input node       : [29] VHS_LoadVideo\n",
            "   Auto-detected field: 'video'\n",
            "\n",
            "ğŸ‘€ Watching '/content/drive/Shareddrives/Figuro/video-upscale/input' every 10s...\n",
            "   Drop files into the input folder to trigger the workflow.\n",
            "   Press Ctrl+C (or stop the cell) to quit.\n",
            "\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ“‚ Processing : 20260213_110317_Copy_of_20260209_1520_01kh0ptyjvecnawm6n864z55de_cleaned.mp4\n",
            "   Started at : 12:38:47\n",
            "FETCH ComfyRegistry Data: 25/125\n",
            "   Node [29].video â†’ '20260213_110317_Copy_of_20260209_1520_01kh0ptyjvecnawm6n864z55de_cleaned.mp4'  (auto-detected)\n",
            "   Prompt ID   : 8a3bf1c0-df16-460a-8c87-1ee775b5ac63\n",
            "   â³ Running workflow...got prompt\n",
            "FETCH ComfyRegistry Data: 30/125\n",
            "FETCH ComfyRegistry Data: 35/125\n",
            "# ğŸ˜ºdzNodes: LayerStyle -> \u001b[1;32mImageScaleByAspectRatio V2 Processed 300 image(s).\u001b[m\n",
            "FETCH ComfyRegistry Data: 40/125\n",
            "\u001b[1;33mDownloading model 'JunhaoZhuang/FlashVSR-v1.1' from huggingface...\u001b[m\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:986: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "FETCH ComfyRegistry Data: 45/125\n",
            "FETCH ComfyRegistry Data: 50/125\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/groupNode.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/widgetInputs.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "FETCH ComfyRegistry Data: 55/125\n",
            "FETCH ComfyRegistry Data: 60/125\n",
            "\n",
            " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
            " â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—\n",
            " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
            " â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â• \n",
            " â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘  â•šâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘   â•šâ•â•\n",
            " â•šâ•â•     â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•   â•šâ•â•   â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•\n",
            "\n",
            "Using wan_video_dit from /content/ComfyUI/models/FlashVSR-v1.1/diffusion_pytorch_model_streaming_dmd.safetensors\n",
            "FETCH ComfyRegistry Data: 65/125\n",
            "FETCH ComfyRegistry Data: 70/125\n",
            "FETCH ComfyRegistry Data: 75/125\n",
            "\u001b[1;33m[FlashVSR] Processing tile 1/6: coords (0,0) to (256,256)\u001b[m\n",
            "FETCH ComfyRegistry Data: 80/125\n",
            "  0% 0/36 [00:00<?, ?it/s]FETCH ComfyRegistry Data: 85/125\n",
            " 25% 9/36 [00:07<00:10,  2.47it/s]FETCH ComfyRegistry Data: 90/125\n",
            " 67% 24/36 [00:12<00:03,  3.05it/s]FETCH ComfyRegistry Data: 95/125\n",
            "100% 36/36 [00:16<00:00,  2.19it/s]\n",
            "[FlashVSR] Starting VAE decoding...\n",
            "FETCH ComfyRegistry Data: 100/125\n",
            "FETCH ComfyRegistry Data: 105/125\n",
            "\u001b[1;33m[FlashVSR] Processing tile 2/6: coords (140,0) to (396,256)\u001b[m\n",
            "FETCH ComfyRegistry Data: 110/125\n",
            " 17% 6/36 [00:02<00:10,  2.82it/s]FETCH ComfyRegistry Data: 115/125\n",
            " 58% 21/36 [00:07<00:04,  3.07it/s]FETCH ComfyRegistry Data: 120/125\n",
            "100% 36/36 [00:12<00:00,  2.94it/s]\n",
            "[FlashVSR] Starting VAE decoding...\n",
            "FETCH ComfyRegistry Data: 125/125\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "\u001b[1;33m[FlashVSR] Processing tile 3/6: coords (0,232) to (256,488)\u001b[m\n",
            "100% 36/36 [00:12<00:00,  2.92it/s]\n",
            "[FlashVSR] Starting VAE decoding...\n",
            "\u001b[1;33m[FlashVSR] Processing tile 4/6: coords (140,232) to (396,488)\u001b[m\n",
            "100% 36/36 [00:12<00:00,  2.89it/s]\n",
            "[FlashVSR] Starting VAE decoding...\n",
            "\u001b[1;33m[FlashVSR] Processing tile 5/6: coords (0,464) to (256,720)\u001b[m\n",
            "100% 36/36 [00:12<00:00,  2.86it/s]\n",
            "[FlashVSR] Starting VAE decoding...\n",
            "\u001b[1;33m[FlashVSR] Processing tile 6/6: coords (140,464) to (396,720)\u001b[m\n",
            "100% 36/36 [00:12<00:00,  2.85it/s]\n",
            "[FlashVSR] Starting VAE decoding...\n",
            "\u001b[1;33m[FlashVSR] Done.\u001b[m\n",
            "Prompt executed in 242.75 seconds\n",
            " done! (1 output(s))\n",
            "   ğŸ’¾ Saved     : /content/drive/Shareddrives/Figuro/video-upscale/output/20260213_110317_Copy_of_20260209_1520_01kh0ptyjvecnawm6n864z55de_cleaned_20260213_124254.mp4\n",
            "   ğŸ“¦ Moved to  : /content/drive/Shareddrives/Figuro/video-upscale/processed/20260213_110317_Copy_of_20260209_1520_01kh0ptyjvecnawm6n864z55de_cleaned.mp4\n"
          ]
        }
      ],
      "source": [
        "import os, time, json, shutil, threading, socket, glob, requests, uuid\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘                     âš™ï¸  CONFIGURATION                           â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# @title âš™ï¸ Configuration\n",
        "# @markdown ---\n",
        "# @markdown ### ğŸ“ Folder Settings\n",
        "# @markdown **Main folder** â€“ all subfolders live here (input / processed / output).\n",
        "# @markdown Can be a Google Drive path or any Colab path.\n",
        "MAIN_FOLDER = \"/content/drive/Shareddrives/Figuro/video-upscale\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **Extra output path** â€“ optional second save location. Leave blank to skip.\n",
        "EXTRA_OUTPUT_PATH = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### ğŸ”„ Workflow Settings\n",
        "# @markdown Filename of your workflow JSON inside MAIN_FOLDER.\n",
        "WORKFLOW_FILENAME = \"FaboroHacks_HD_video_upscale_V1_api.json\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### ğŸ¯ Input Node Config\n",
        "# @markdown The node ID where the input file is injected.\n",
        "# @markdown Find it by opening your workflow JSON â€” the top-level numeric key of your\n",
        "# @markdown Load Image / Load Video node (e.g. \"12\"). The input field is auto-detected.\n",
        "INPUT_NODE_ID = \"29\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### â±ï¸ Watcher Settings\n",
        "# @markdown How often (seconds) to check the input folder for new files.\n",
        "POLL_INTERVAL = 10  # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown Supported file extensions to watch for.\n",
        "SUPPORTED_EXTENSIONS = \"png,jpg,jpeg,webp,mp4,gif,bmp,tiff\"  # @param {type:\"string\"}\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘                   ğŸ”§  SETUP & HELPERS                           â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "COMFYUI_URL   = \"http://127.0.0.1:8188\"\n",
        "INPUT_FOLDER  = os.path.join(MAIN_FOLDER, \"input\")\n",
        "PROCESSED_DIR = os.path.join(MAIN_FOLDER, \"processed\")\n",
        "OUTPUT_DIR    = os.path.join(MAIN_FOLDER, \"output\")\n",
        "WORKFLOW_PATH = os.path.join(MAIN_FOLDER, WORKFLOW_FILENAME)\n",
        "\n",
        "EXTRA_OUTPUT_PATH = EXTRA_OUTPUT_PATH.strip()\n",
        "EXTRA_DIR = EXTRA_OUTPUT_PATH if EXTRA_OUTPUT_PATH else None\n",
        "\n",
        "EXTENSIONS = {e.strip().lower().lstrip('.') for e in SUPPORTED_EXTENSIONS.split(',') if e.strip()}\n",
        "\n",
        "# Known field names that carry a file/image path, in priority order\n",
        "_FILE_FIELDS = [\n",
        "    \"image\", \"video\", \"audio\", \"file\", \"mask\",\n",
        "    \"image_path\", \"video_path\", \"file_path\",\n",
        "    \"input\", \"source\", \"path\",\n",
        "]\n",
        "\n",
        "for d in [INPUT_FOLDER, PROCESSED_DIR, OUTPUT_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "if EXTRA_DIR:\n",
        "    os.makedirs(EXTRA_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def load_workflow() -> dict:\n",
        "    \"\"\"Load the workflow JSON from disk (re-read every run so edits take effect).\"\"\"\n",
        "    if not os.path.exists(WORKFLOW_PATH):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Workflow not found: {WORKFLOW_PATH}\\n\"\n",
        "            \"Export your workflow in API format from ComfyUI and save it there.\"\n",
        "        )\n",
        "    with open(WORKFLOW_PATH, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def auto_detect_field(workflow: dict, node_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Auto-detect which input field of a node holds the file path.\n",
        "    Strategy:\n",
        "      1. Check against known field name list (priority order).\n",
        "      2. Fall back to any field whose current value is a string ending with\n",
        "         a known image/video extension.\n",
        "      3. Fall back to any string field that isn't a URL or long prompt text.\n",
        "    Raises ValueError with a helpful message if nothing is found.\n",
        "    \"\"\"\n",
        "    if node_id not in workflow:\n",
        "        raise KeyError(\n",
        "            f\"Node '{node_id}' not found in workflow.\\n\"\n",
        "            f\"Available node IDs: {list(workflow.keys())}\"\n",
        "        )\n",
        "\n",
        "    inputs = workflow[node_id].get(\"inputs\", {})\n",
        "\n",
        "    # 1. Priority match against known field names\n",
        "    for known in _FILE_FIELDS:\n",
        "        if known in inputs:\n",
        "            return known\n",
        "\n",
        "    # 2. Any field whose value looks like a filename with a media extension\n",
        "    media_exts = {\n",
        "        \"png\",\"jpg\",\"jpeg\",\"webp\",\"gif\",\"bmp\",\"tiff\",\"tif\",\n",
        "        \"mp4\",\"avi\",\"mov\",\"mkv\",\"webm\",\n",
        "        \"mp3\",\"wav\",\"flac\",\"ogg\",\n",
        "    }\n",
        "    for field, val in inputs.items():\n",
        "        if isinstance(val, str) and Path(val).suffix.lower().lstrip('.') in media_exts:\n",
        "            return field\n",
        "\n",
        "    # 3. Any plain string field that isn't suspiciously long (i.e. not a prompt)\n",
        "    short_strings = [\n",
        "        field for field, val in inputs.items()\n",
        "        if isinstance(val, str) and len(val) < 256 and not val.startswith((\"http\", \"{\"))\n",
        "    ]\n",
        "    if short_strings:\n",
        "        return short_strings[0]\n",
        "\n",
        "    raise ValueError(\n",
        "        f\"Could not auto-detect an input file field on node '{node_id}'.\\n\"\n",
        "        f\"Node inputs: {list(inputs.keys())}\\n\"\n",
        "        f\"Rename one of those fields to 'image' or 'video', or check your node ID.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def wait_for_comfyui(timeout: int = 120):\n",
        "    \"\"\"Block until ComfyUI HTTP server responds.\"\"\"\n",
        "    print(\"â³ Waiting for ComfyUI to start...\", end=\"\", flush=True)\n",
        "    deadline = time.time() + timeout\n",
        "    while time.time() < deadline:\n",
        "        try:\n",
        "            r = requests.get(f\"{COMFYUI_URL}/system_stats\", timeout=3)\n",
        "            if r.status_code == 200:\n",
        "                print(\" âœ… Ready!\")\n",
        "                return\n",
        "        except Exception:\n",
        "            pass\n",
        "        print(\".\", end=\"\", flush=True)\n",
        "        time.sleep(2)\n",
        "    raise TimeoutError(\"ComfyUI did not start within the timeout window.\")\n",
        "\n",
        "\n",
        "def queue_prompt(workflow: dict) -> str:\n",
        "    \"\"\"Submit workflow to ComfyUI and return the prompt_id.\"\"\"\n",
        "    client_id = str(uuid.uuid4())\n",
        "    payload = {\"prompt\": workflow, \"client_id\": client_id}\n",
        "    r = requests.post(f\"{COMFYUI_URL}/prompt\", json=payload, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    if \"error\" in data:\n",
        "        raise RuntimeError(f\"ComfyUI prompt error: {data['error']}\")\n",
        "    return data[\"prompt_id\"]\n",
        "\n",
        "\n",
        "def poll_until_done(prompt_id: str, timeout: int = 600) -> list:\n",
        "    \"\"\"Poll /history until the prompt finishes; return list of output file info dicts.\"\"\"\n",
        "    deadline = time.time() + timeout\n",
        "    while time.time() < deadline:\n",
        "        time.sleep(3)\n",
        "        try:\n",
        "            r = requests.get(f\"{COMFYUI_URL}/history/{prompt_id}\", timeout=10)\n",
        "            r.raise_for_status()\n",
        "            history = r.json()\n",
        "        except Exception:\n",
        "            continue\n",
        "        if prompt_id not in history:\n",
        "            continue\n",
        "        entry = history[prompt_id]\n",
        "        outputs = []\n",
        "        for node_id, node_out in entry.get(\"outputs\", {}).items():\n",
        "            for key, items in node_out.items():\n",
        "                if isinstance(items, list):\n",
        "                    for item in items:\n",
        "                        if isinstance(item, dict) and \"filename\" in item:\n",
        "                            outputs.append(item)\n",
        "        return outputs\n",
        "    raise TimeoutError(f\"Prompt {prompt_id} did not finish within {timeout}s\")\n",
        "\n",
        "\n",
        "def fetch_and_save_output(file_info: dict, dest_dirs: list, stem: str) -> list:\n",
        "    \"\"\"Download a single output file from ComfyUI and save to all dest_dirs.\"\"\"\n",
        "    filename  = file_info[\"filename\"]\n",
        "    subfolder = file_info.get(\"subfolder\", \"\")\n",
        "    ftype     = file_info.get(\"type\", \"output\")\n",
        "\n",
        "    params = {\"filename\": filename, \"subfolder\": subfolder, \"type\": ftype}\n",
        "    r = requests.get(f\"{COMFYUI_URL}/view\", params=params, timeout=120)\n",
        "    r.raise_for_status()\n",
        "\n",
        "    ext = Path(filename).suffix\n",
        "    ts  = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    save_name = f\"{stem}_{ts}{ext}\"\n",
        "\n",
        "    saved = []\n",
        "    for dest in dest_dirs:\n",
        "        os.makedirs(dest, exist_ok=True)\n",
        "        out_path = os.path.join(dest, save_name)\n",
        "        with open(out_path, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "        saved.append(out_path)\n",
        "    return saved\n",
        "\n",
        "\n",
        "def copy_input_to_comfyui(src_path: str) -> str:\n",
        "    \"\"\"Copy the input file into ComfyUI's own input folder; return the filename.\"\"\"\n",
        "    comfyui_input = \"/content/ComfyUI/input\"\n",
        "    os.makedirs(comfyui_input, exist_ok=True)\n",
        "    filename = Path(src_path).name\n",
        "    shutil.copy2(src_path, os.path.join(comfyui_input, filename))\n",
        "    return filename\n",
        "\n",
        "\n",
        "def process_file(filepath: str):\n",
        "    \"\"\"Run one input file through the workflow end-to-end.\"\"\"\n",
        "    stem = Path(filepath).stem\n",
        "    print(f\"\\n{'â”€'*55}\")\n",
        "    print(f\"ğŸ“‚ Processing : {Path(filepath).name}\")\n",
        "    print(f\"   Started at : {datetime.now().strftime('%H:%M:%S')}\")\n",
        "\n",
        "    # 1. Load workflow fresh (picks up any edits without restarting)\n",
        "    workflow = load_workflow()\n",
        "\n",
        "    # 2. Auto-detect the file input field on the configured node\n",
        "    detected_field = auto_detect_field(workflow, INPUT_NODE_ID)\n",
        "\n",
        "    # 3. Copy file into ComfyUI input dir and inject filename into the node\n",
        "    input_filename = copy_input_to_comfyui(filepath)\n",
        "    workflow[INPUT_NODE_ID][\"inputs\"][detected_field] = input_filename\n",
        "    print(f\"   Node [{INPUT_NODE_ID}].{detected_field} â†’ '{input_filename}'  (auto-detected)\")\n",
        "\n",
        "    # 4. Queue\n",
        "    prompt_id = queue_prompt(workflow)\n",
        "    print(f\"   Prompt ID   : {prompt_id}\")\n",
        "\n",
        "    # 5. Wait for completion\n",
        "    print(\"   â³ Running workflow...\", end=\"\", flush=True)\n",
        "    output_files = poll_until_done(prompt_id)\n",
        "    print(f\" done! ({len(output_files)} output(s))\")\n",
        "\n",
        "    # 6. Save all outputs\n",
        "    dest_dirs = [OUTPUT_DIR]\n",
        "    if EXTRA_DIR:\n",
        "        dest_dirs.append(EXTRA_DIR)\n",
        "\n",
        "    saved_paths = []\n",
        "    for file_info in output_files:\n",
        "        paths = fetch_and_save_output(file_info, dest_dirs, stem)\n",
        "        saved_paths.extend(paths)\n",
        "        for p in paths:\n",
        "            print(f\"   ğŸ’¾ Saved     : {p}\")\n",
        "\n",
        "    if not saved_paths:\n",
        "        print(\"   âš ï¸  No downloadable outputs (check workflow has a SaveImage / Save node).\")\n",
        "\n",
        "    # 7. Move input to processed\n",
        "    dest_processed = os.path.join(PROCESSED_DIR, Path(filepath).name)\n",
        "    if os.path.exists(dest_processed):\n",
        "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        dest_processed = os.path.join(PROCESSED_DIR, f\"{stem}_{ts}{Path(filepath).suffix}\")\n",
        "    shutil.move(filepath, dest_processed)\n",
        "    print(f\"   ğŸ“¦ Moved to  : {dest_processed}\")\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘                 ğŸš€  LAUNCH COMFYUI + WATCHER                    â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def run_watcher():\n",
        "    \"\"\"Background thread: poll input folder and process new files.\"\"\"\n",
        "    wait_for_comfyui()\n",
        "\n",
        "    # Validate node + field detection once on startup with a dry-run\n",
        "    try:\n",
        "        wf = load_workflow()\n",
        "        field = auto_detect_field(wf, INPUT_NODE_ID)\n",
        "        node_class = wf[INPUT_NODE_ID].get(\"class_type\", \"unknown\")\n",
        "        print(f\"\\nâœ… Workflow loaded  : {WORKFLOW_PATH}\")\n",
        "        print(f\"   Input node       : [{INPUT_NODE_ID}] {node_class}\")\n",
        "        print(f\"   Auto-detected field: '{field}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâš ï¸  Workflow pre-check failed: {e}\")\n",
        "        print(\"   Fix the issue above and restart the cell.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nğŸ‘€ Watching '{INPUT_FOLDER}' every {POLL_INTERVAL}s...\")\n",
        "    print(\"   Drop files into the input folder to trigger the workflow.\")\n",
        "    print(\"   Press Ctrl+C (or stop the cell) to quit.\\n\")\n",
        "\n",
        "    seen_errors = {}  # filepath â†’ error count\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            candidates = []\n",
        "            for ext in EXTENSIONS:\n",
        "                candidates.extend(glob.glob(os.path.join(INPUT_FOLDER, f\"*.{ext}\")))\n",
        "                candidates.extend(glob.glob(os.path.join(INPUT_FOLDER, f\"*.{ext.upper()}\")))\n",
        "            candidates = sorted(set(candidates))\n",
        "\n",
        "            if not candidates:\n",
        "                time.sleep(POLL_INTERVAL)\n",
        "                continue\n",
        "\n",
        "            for fp in candidates:\n",
        "                if seen_errors.get(fp, 0) >= 3:\n",
        "                    continue\n",
        "                try:\n",
        "                    process_file(fp)\n",
        "                    seen_errors.pop(fp, None)\n",
        "                except Exception as e:\n",
        "                    seen_errors[fp] = seen_errors.get(fp, 0) + 1\n",
        "                    count = seen_errors[fp]\n",
        "                    print(f\"\\nâŒ Error ({count}/3) â€” {Path(fp).name}: {e}\")\n",
        "                    if count >= 3:\n",
        "                        print(f\"   â›” Giving up on {Path(fp).name}.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  Watcher loop error: {e}\")\n",
        "\n",
        "        time.sleep(POLL_INTERVAL)\n",
        "\n",
        "\n",
        "def iframe_thread(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        if sock.connect_ex(('127.0.0.1', port)) == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "    from google.colab import output as colab_output\n",
        "    print(\"\\nğŸŒ ComfyUI is ready! Opening in iframe below...\")\n",
        "    print(\"ğŸ’¡ Tip: Click the link to open in a new window\\n\")\n",
        "    colab_output.serve_kernel_port_as_iframe(port, height=900)\n",
        "    colab_output.serve_kernel_port_as_window(port)\n",
        "\n",
        "\n",
        "# Print startup summary\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ—‚ï¸  ComfyUI Batch Workflow Runner\")\n",
        "print(\"=\"*60)\n",
        "print(f\"  Main folder   : {MAIN_FOLDER}\")\n",
        "print(f\"  Input         : {INPUT_FOLDER}\")\n",
        "print(f\"  Processed     : {PROCESSED_DIR}\")\n",
        "print(f\"  Output        : {OUTPUT_DIR}\")\n",
        "if EXTRA_DIR:\n",
        "    print(f\"  Extra output  : {EXTRA_DIR}\")\n",
        "print(f\"  Workflow      : {WORKFLOW_PATH}\")\n",
        "print(f\"  Input node ID : {INPUT_NODE_ID}  (field auto-detected at runtime)\")\n",
        "print(f\"  Poll interval : {POLL_INTERVAL}s\")\n",
        "print(f\"  Extensions    : {', '.join(sorted(EXTENSIONS))}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "%cd /content/ComfyUI\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "threading.Thread(target=run_watcher, daemon=True).start()\n",
        "\n",
        "print(\"\\nğŸš€ Starting ComfyUI + Batch Watcher...\")\n",
        "print(\"â³ Please wait for the interface to load below...\\n\")\n",
        "\n",
        "!python main.py --dont-print-server\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "notes"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“ Notes\n",
        "\n",
        "- **Workflow format**: Export using ComfyUI â†’ Settings â†’ Dev Mode â†’ *Save (API Format)*. The API format uses numeric node IDs as top-level keys.\n",
        "- **Input node ID**: Open your `workflow.json` and find the node that loads images/files (e.g. `LoadImage`, `VHS_LoadVideo`). Its top-level key (e.g. `\"12\"`) is the `INPUT_NODE_ID`.\n",
        "- **Field auto-detection**: The runner inspects the node's inputs and picks the first field that looks like a file path â€” checking against known names (`image`, `video`, `audio`, `file`, â€¦) then by value type. The detected field is printed at startup so you can verify it.\n",
        "- **Output capture**: All nodes that produce files (SaveImage, VHS_VideoCombine, etc.) are captured automatically.\n",
        "- **Extra output**: Set `EXTRA_OUTPUT_PATH` to copy outputs to a second destination (e.g. another Drive folder).\n",
        "- **Error handling**: Files that fail 3 times are permanently skipped so the watcher doesn't loop forever.\n",
        "- **Live edits**: The workflow JSON is re-read on every file, so you can tweak it without restarting.\n",
        "\n",
        "---\n",
        "\n",
        "**Enjoy using ComfyUI Batch Runner! ğŸ¨**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}