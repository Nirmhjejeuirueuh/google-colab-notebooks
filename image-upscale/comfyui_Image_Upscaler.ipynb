{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mbkK_HkVhjL"
      },
      "source": [
        "# ğŸ–¼ï¸ ComfyUI Colab â€” Image Upscaler\n",
        "\n",
        "Batch upscale images from Google Drive using ComfyUI. Drop files in, get results out.\n",
        "\n",
        "**Run cells top to bottom.** Code is hidden by default â€” expand to edit.\n",
        "\n",
        "---\n",
        "| Step | What it does |\n",
        "|------|-------------|\n",
        "| 1 Â· Mount Drive | Connects My Drive or Shared Drive |\n",
        "| 2 Â· Install | ComfyUI + speed stack (xformers, triton, sageattention) |\n",
        "| 3 Â· Custom Nodes | Install upscaler nodes from GitHub |\n",
        "| 4 Â· Models | Download upscale models (Real-ESRGAN etc.) |\n",
        "| 5 Â· Launch | Starts ComfyUI + watches input folder for new images |\n",
        "\n",
        "---\n",
        "### â–¶ï¸ How to run\n",
        "\n",
        "1. Upload images to your Drive input folder â€” `<your root folder>/input/`\n",
        "2. In cell 5, choose your mode:\n",
        "   - `QUALITY_MODE = False` â€” uses **Real-ESRGAN**, fast, best for digital art & anime\n",
        "   - `QUALITY_MODE = True` â€” uses **SeedVR2**, slower, best for real photos\n",
        "3. Run **Runtime â†’ Run all**\n",
        "4. Wait for all images to process â€” outputs appear in `<your root folder>/output/`\n",
        "5. When done, go to **Runtime â†’ Disconnect and delete runtime** to stop billing"
      ],
      "id": "-mbkK_HkVhjL"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MONdY9l1VhjM",
        "outputId": "41afd254-4c7b-4bdd-8318-ba3528bfca01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‚ Connecting to Google Drive...\n",
            "Mounted at /content/drive\n",
            "âœ… Shared Drives detected.\n",
            "âœ… Drive mount complete.\n"
          ]
        }
      ],
      "source": [
        "# @title ğŸ“‚ 1 Â· Mount Google Drive { display-mode: \"form\" }\n",
        "# @markdown Mounts Google Drive (My Drive + Shared Drives). Run this first before any other cell.\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"ğŸ“‚ Connecting to Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Verify access\n",
        "if os.path.exists(\"/content/drive/Shareddrives\"):\n",
        "    print(\"âœ… Shared Drives detected.\")\n",
        "elif os.path.exists(\"/content/drive/Shared drives\"):\n",
        "    print(\"âœ… Shared Drives detected (alternate path).\")\n",
        "else:\n",
        "    print(\"â„¹ï¸  Only MyDrive detected.\")\n",
        "\n",
        "print(\"âœ… Drive mount complete.\")\n"
      ],
      "id": "MONdY9l1VhjM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2yNfUx5VhjN"
      },
      "outputs": [],
      "source": [
        "# @title âš™ï¸ Install ComfyUI & Dependencies { display-mode: \"form\" }\n",
        "# @markdown ## 2 Â· Install ComfyUI & Dependencies\n",
        "# @markdown\n",
        "# @markdown Clones ComfyUI and installs the full stack including the **speed trio**:\n",
        "# @markdown - **xformers** â€” faster attention, lower VRAM\n",
        "# @markdown - **triton** â€” GPU kernel acceleration\n",
        "# @markdown - **sageattention** â€” additional attention optimization\n",
        "# @markdown\n",
        "# @markdown Also sets `PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True` to reduce OOM crashes.\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "WORKSPACE = \"/content/ComfyUI\"\n",
        "\n",
        "# â”€â”€ 0. Install uv â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"ğŸ“¦ Installing uv...\")\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "os.environ[\"PATH\"] = \"/root/.local/bin:\" + os.environ[\"PATH\"]\n",
        "print(\"âœ… uv ready\\n\")\n",
        "\n",
        "# â”€â”€ 1. Clone / update ComfyUI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if not os.path.exists(WORKSPACE):\n",
        "    print(\"ğŸ“¥ Cloning ComfyUI...\")\n",
        "    !git clone -q https://github.com/comfyanonymous/ComfyUI {WORKSPACE}\n",
        "    print(\"âœ… Cloned\\n\")\n",
        "else:\n",
        "    print(\"âœ… ComfyUI exists, pulling updates...\")\n",
        "    !cd {WORKSPACE} && git pull -q\n",
        "    print(\"âœ… Updated\\n\")\n",
        "\n",
        "%cd {WORKSPACE}\n",
        "\n",
        "# â”€â”€ 2. PyTorch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"âš¡ Installing PyTorch 2.8.0...\")\n",
        "!uv pip install --system torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --no-deps\n",
        "\n",
        "# â”€â”€ 3. Speed stack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"ğŸš€ Installing speed stack...\")\n",
        "!uv pip install --system --upgrade xformers triton sageattention\n",
        "\n",
        "# â”€â”€ 4. ComfyUI requirements â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"ğŸ“¦ Installing ComfyUI requirements...\")\n",
        "!uv pip install --system -r requirements.txt\n",
        "\n",
        "# â”€â”€ 5. Core dependencies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"ğŸ“š Installing core dependencies...\")\n",
        "!uv pip install --system \\\n",
        "    accelerate einops diffusers \\\n",
        "    \"safetensors>=0.4.2\" \\\n",
        "    aiohttp pyyaml Pillow scipy tqdm psutil \\\n",
        "    \"tokenizers>=0.13.3\" sentencepiece soundfile \\\n",
        "    \"kornia>=0.7.1\" spandrel torchsde \\\n",
        "    av albumentations opencv-python \\\n",
        "    onnxruntime-gpu color-matcher \\\n",
        "    comfy_aimdo comfy-kitchen\n",
        "\n",
        "# â”€â”€ 6. Transformers / HuggingFace â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"ğŸ¤— Installing transformers & huggingface-hub...\")\n",
        "!uv pip install --system \\\n",
        "    \"transformers>=4.45.0,<5.0.0\" \\\n",
        "    \"huggingface-hub>=0.23.0\" \\\n",
        "    hf_transfer\n",
        "\n",
        "# â”€â”€ 7. CUDA memory optimization â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "print(\"âœ… CUDA memory config set\\n\")\n",
        "\n",
        "# â”€â”€ 8. ComfyUI Manager â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "manager_path = f\"{WORKSPACE}/custom_nodes/ComfyUI-Manager\"\n",
        "if not os.path.exists(manager_path):\n",
        "    print(\"ğŸ“¥ Installing ComfyUI Manager...\")\n",
        "    !git clone -q https://github.com/ltdrdata/ComfyUI-Manager {manager_path}\n",
        "else:\n",
        "    print(\"ğŸ”„ Updating ComfyUI Manager...\")\n",
        "    !cd {manager_path} && git pull -q\n",
        "print(\"âœ… ComfyUI Manager ready\\n\")\n",
        "\n",
        "# â”€â”€ 9. Verify â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import importlib.metadata as meta\n",
        "print(\"ğŸ“‹ Key package versions:\")\n",
        "for pkg in [\"torch\", \"xformers\", \"transformers\", \"huggingface-hub\", \"safetensors\"]:\n",
        "    try:\n",
        "        print(f\"  âœ… {pkg}: {meta.version(pkg)}\")\n",
        "    except Exception:\n",
        "        print(f\"  âŒ {pkg}: not found\")\n",
        "\n",
        "print(\"\\nğŸ‰ Installation complete! Run the next cell.\")\n"
      ],
      "id": "F2yNfUx5VhjN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEhYXZBNVhjN"
      },
      "outputs": [],
      "source": [
        "# @title ğŸ”§ 3 Â· Custom Nodes { display-mode: \"form\" }\n",
        "# @markdown Add GitHub repos to `CUSTOM_NODES` below and uncomment to install.\n",
        "# @markdown Re-running is safe â€” existing nodes are skipped automatically.\n",
        "import os, shutil\n",
        "\n",
        "# â”€â”€â”€ CONFIGURATION â”€â”€â”€\n",
        "WORKSPACE        = \"/content/ComfyUI\"\n",
        "CUSTOM_NODES_DIR = f\"{WORKSPACE}/custom_nodes\"\n",
        "\n",
        "# Add any GitHub URL here. Format: (\"Folder_Name\", \"URL\")\n",
        "CUSTOM_NODES = [\n",
        "    (\"rgthree-comfy\",\"https://github.com/rgthree/rgthree-comfy\"),\n",
        "    (\"ComfyUI-SeedVR2_VideoUpscaler\",\"https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler\"),\n",
        "]\n",
        "\n",
        "# â”€â”€â”€ INSTALLATION LOGIC â”€â”€â”€\n",
        "print(\"ğŸš€ Starting Custom Node Installation...\\n\")\n",
        "\n",
        "for name, url in CUSTOM_NODES:\n",
        "    path = os.path.join(CUSTOM_NODES_DIR, name)\n",
        "\n",
        "    # 1. FIX BROKEN DOWNLOADS\n",
        "    # If folder exists but isn't a git repo, it's a failed download from a previous run.\n",
        "    if os.path.exists(path) and not os.path.exists(os.path.join(path, \".git\")):\n",
        "        print(f\"âš ï¸ Found broken folder '{name}', cleaning up...\")\n",
        "        shutil.rmtree(path)\n",
        "\n",
        "    # 2. CLONE REPO\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"ğŸ“¥ Cloning: {name}\")\n",
        "        # We use ! instead of os.system to see real-time progress and errors\n",
        "        !git clone {url} {path}\n",
        "    else:\n",
        "        print(f\"â­ï¸  Already exists: {name}\")\n",
        "        # Optional: update existing nodes\n",
        "        # !cd {path} && git pull\n",
        "\n",
        "    # 3. INSTALL REQUIREMENTS\n",
        "    req_file = os.path.join(path, \"requirements.txt\")\n",
        "    if os.path.exists(req_file):\n",
        "        print(f\"ğŸ“¦ Installing dependencies for {name}...\")\n",
        "        # We removed -q so you can see if a specific library fails to install\n",
        "        !uv pip install --system -r {req_file}\n",
        "    else:\n",
        "        print(f\"â„¹ï¸  No requirements.txt for {name}\")\n",
        "\n",
        "print(\"\\nâœ¨ All custom nodes processed.\")"
      ],
      "id": "IEhYXZBNVhjN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13-v_fw6VhjO"
      },
      "outputs": [],
      "source": [
        "# @title ğŸ“¥ 4 Â· Download Models { display-mode: \"form\" }\n",
        "# @markdown Add as many models as you want in the list below.<br>\n",
        "# @markdown - For **Hugging Face** â†’ use `\"type\": \"hf\"` + `repo_id` + optional `filename` (None = full repo).<br>\n",
        "# @markdown - For **Civitai / mirrors / other** â†’ use `\"type\": \"url\"` + direct `url` + `filename`.\n",
        "\n",
        "import os\n",
        "from huggingface_hub import hf_hub_download, snapshot_download\n",
        "from tqdm import tqdm\n",
        "import subprocess\n",
        "\n",
        "# Install aria2c (required for fast URL downloads)\n",
        "!apt-get update -qq && apt-get install -y -qq aria2\n",
        "print(\"âœ… aria2c installed\\n\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#   â†“â†“â†“  ADD / EDIT YOUR MODELS HERE  â†“â†“â†“\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "downloads = [\n",
        "    # SeedVR2 models (from AInVFX / numz repos â€” HF â†’ fast hf_transfer)\n",
        "    # Example: Add more HF models (single file or full repo)\n",
        "    {\n",
        "        \"type\": \"hf\",\n",
        "        \"repo_id\": \"numz/SeedVR2_comfyUI\",\n",
        "        \"filename\": \"seedvr2_ema_7b_fp16.safetensors\",                           # None = download entire repo\n",
        "        \"folder\": \"models/SEEDVR2\",\n",
        "    },\n",
        "\n",
        "    # Example: Non-HF download (Civitai / mirror) â†’ uses aria2c\n",
        "    {\n",
        "        \"type\": \"url\",\n",
        "        \"url\": \"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth\",\n",
        "        \"filename\": \"RealESRGAN_x4plus_anime_6B.pth\",\n",
        "        \"folder\": \"models/upscale_models\",\n",
        "    },\n",
        "]\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#     Usually no need to change anything below\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "base_dir = \"/content/ComfyUI\"\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"   # Enables fast Rust-accelerated HF downloads\n",
        "\n",
        "for item in tqdm(downloads, desc=\"Downloading models\"):\n",
        "    target_folder = os.path.join(base_dir, item[\"folder\"].lstrip(\"/\"))\n",
        "    os.makedirs(target_folder, exist_ok=True)\n",
        "\n",
        "    if item[\"type\"].lower() in [\"hf\", \"huggingface\"]:\n",
        "        repo = item[\"repo_id\"]\n",
        "        file = item.get(\"filename\")\n",
        "        print(f\"\\nğŸ“¥ HF   â†’ {repo}  â†’  {file or 'FULL REPO'}\")\n",
        "\n",
        "        try:\n",
        "            if file is None:\n",
        "                snapshot_download(\n",
        "                    repo_id=repo,\n",
        "                    local_dir=target_folder,\n",
        "                    local_dir_use_symlinks=False,\n",
        "                    resume_download=True,\n",
        "                )\n",
        "            else:\n",
        "                hf_hub_download(\n",
        "                    repo_id=repo,\n",
        "                    filename=file,\n",
        "                    local_dir=target_folder,\n",
        "                    resume_download=True,\n",
        "                )\n",
        "        except Exception as e:\n",
        "            print(f\"  âš ï¸ Error with HF download: {e}\")\n",
        "            print(\"   â†’ Check repo_id / filename or try manual URL with type:url\")\n",
        "\n",
        "    elif item[\"type\"].lower() == \"url\":\n",
        "        url = item[\"url\"]\n",
        "        fname = item[\"filename\"]\n",
        "        print(f\"\\nğŸ“¥ URL  â†’ {url}  â†’  {fname}\")\n",
        "\n",
        "        cmd = [\n",
        "            \"aria2c\", \"--console-log-level=error\", \"-c\",\n",
        "            \"-x\", \"16\", \"-s\", \"16\", \"-j\", \"8\", \"-k\", \"1M\",\n",
        "            url, \"-d\", target_folder, \"-o\", fname\n",
        "        ]\n",
        "        try:\n",
        "            subprocess.run(cmd, check=True)\n",
        "        except Exception as e:\n",
        "            print(f\"  âš ï¸ aria2c failed: {e}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"âš ï¸ Unknown type '{item['type']}' â€” skipping\")\n",
        "\n",
        "print(\"\\nâœ… All downloads finished! Check folders in /content/ComfyUI/models/\")"
      ],
      "id": "13-v_fw6VhjO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0zKPtIoVhjP"
      },
      "outputs": [],
      "source": [
        "# @title ğŸš€ Launch ComfyUI { display-mode: \"form\" }\n",
        "# @markdown ## 5 Â· Launch ComfyUI\n",
        "# @markdown\n",
        "# @markdown Choose launch mode and configure the batch watcher below.\n",
        "# @markdown\n",
        "# @markdown **Launch modes:**\n",
        "# @markdown - `window` â€” opens ComfyUI in a new browser tab (default)\n",
        "# @markdown - `iframe` â€” embeds ComfyUI inside the notebook cell\n",
        "# @markdown - `cloudflare` â€” public URL via Cloudflare tunnel (share across devices)\n",
        "# @markdown\n",
        "# @markdown **Batch watcher** monitors an input folder and auto-runs a workflow on every dropped file.\n",
        "# @markdown Set `BATCH_MODE = False` to just launch ComfyUI without the watcher.\n",
        "import os, time, json, shutil, threading, socket, glob, requests, uuid, subprocess\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# paste this right after the imports, before CONFIGURATION\n",
        "import builtins\n",
        "if getattr(builtins, \"_comfyui_launched\", False):\n",
        "    print(\"âš ï¸  Already running. Use Runtime â†’ Restart to relaunch.\")\n",
        "    raise SystemExit()\n",
        "builtins._comfyui_launched = True\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  âš™ï¸  CONFIGURATION                                              â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "LAUNCH_MODE  = \"window\"     # @param [\"window\", \"iframe\", \"cloudflare\"]\n",
        "BATCH_MODE   = True          # @param {type:\"boolean\"}\n",
        "\n",
        "# Full absolute path â€” examples:\n",
        "# My Drive    : /content/drive/MyDrive/comfyui/image-upscale\n",
        "# Shared Drive: /content/drive/Shareddrives/Figuro/image-upscale\n",
        "DRIVE_BASE_PATH      = \"/content/drive/Shareddrives/Figuro/image-upscale\"  # @param {type:\"string\"}\n",
        "EXTRA_OUTPUT_PATH    = \"\"                                       # @param {type:\"string\"}\n",
        "QUALITY_MODE         = False                                         # @param {type:\"boolean\"}\n",
        "WORKFLOW_FILENAME    = \"workflow_api.json\" if QUALITY_MODE else \"fast_workflow_api.json\"\n",
        "INPUT_NODE_ID        = \"15\"                                      # @param {type:\"string\"}\n",
        "POLL_INTERVAL        = 10                                       # @param {type:\"integer\"}\n",
        "SUPPORTED_EXTENSIONS = \"png,jpg,jpeg,webp,mp4,gif,bmp,tiff\"   # @param {type:\"string\"}\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  ğŸ”  PATH RESOLUTION (works with Shared Drives + MyDrive)      â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "from google.colab import drive as _drive\n",
        "if not os.path.exists(\"/content/drive\"):\n",
        "    _drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def validate_path(label: str, path: str) -> str:\n",
        "    path = path.strip().rstrip(\"/\")\n",
        "    if not path.startswith(\"/content/drive/\"):\n",
        "        raise ValueError(f\"âŒ {label} must start with /content/drive/MyDrive/... or /content/drive/Shareddrives/<name>/...\\n   Got: '{path}'\")\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    return path\n",
        "\n",
        "def safe_makedirs(path: str) -> str:\n",
        "    \"\"\"Create a subdir inside an existing Drive folder. Falls back to /tmp on error.\"\"\"\n",
        "    try:\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        return path\n",
        "    except OSError as e:\n",
        "        fallback = path.replace(\"/content/drive\", \"/tmp/drive_mirror\")\n",
        "        os.makedirs(fallback, exist_ok=True)\n",
        "        print(f\"âš ï¸  Cannot create '{path}': {e}\")\n",
        "        print(f\"   â†’ Using local fallback: '{fallback}'\")\n",
        "        print(f\"   â†’ Fix: create the folder manually in Drive, then re-run.\")\n",
        "        return fallback\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  ğŸ”§  SETUP                                                      â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "COMFYUI_URL = \"http://127.0.0.1:8188\"\n",
        "EXTENSIONS  = {e.strip().lower().lstrip('.') for e in SUPPORTED_EXTENSIONS.split(',') if e.strip()}\n",
        "_FILE_FIELDS = [\"image\",\"video\",\"audio\",\"file\",\"mask\",\n",
        "                \"image_path\",\"video_path\",\"file_path\",\"input\",\"source\",\"path\"]\n",
        "\n",
        "if BATCH_MODE:\n",
        "    MAIN_FOLDER   = validate_path(\"DRIVE_BASE_PATH\", DRIVE_BASE_PATH)\n",
        "    INPUT_FOLDER  = safe_makedirs(os.path.join(MAIN_FOLDER, \"input\"))\n",
        "    PROCESSED_DIR = safe_makedirs(os.path.join(MAIN_FOLDER, \"processed\"))\n",
        "    OUTPUT_DIR    = safe_makedirs(os.path.join(MAIN_FOLDER, \"output\"))\n",
        "    WORKFLOW_PATH = os.path.join(MAIN_FOLDER, WORKFLOW_FILENAME)\n",
        "    EXTRA_DIR     = None\n",
        "    if EXTRA_OUTPUT_PATH.strip():\n",
        "        EXTRA_DIR = validate_path(\"EXTRA_OUTPUT_PATH\", EXTRA_OUTPUT_PATH.strip())\n",
        "    print(f\"âœ… Paths ready:\")\n",
        "    print(f\"   Input     : {INPUT_FOLDER}\")\n",
        "    print(f\"   Processed : {PROCESSED_DIR}\")\n",
        "    print(f\"   Output    : {OUTPUT_DIR}\")\n",
        "    print(f\"   Workflow  : {WORKFLOW_PATH}\")\n",
        "else:\n",
        "    MAIN_FOLDER = WORKFLOW_PATH = INPUT_FOLDER = PROCESSED_DIR = OUTPUT_DIR = EXTRA_DIR = None\n",
        "\n",
        "# â”€â”€ Batch helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def load_workflow():\n",
        "    if not os.path.exists(WORKFLOW_PATH):\n",
        "        raise FileNotFoundError(f\"Workflow not found: {WORKFLOW_PATH}\")\n",
        "    with open(WORKFLOW_PATH) as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def auto_detect_field(workflow, node_id):\n",
        "    if node_id not in workflow:\n",
        "        raise KeyError(f\"Node '{node_id}' not found. Available: {list(workflow.keys())}\")\n",
        "    inputs = workflow[node_id].get(\"inputs\", {})\n",
        "    for known in _FILE_FIELDS:\n",
        "        if known in inputs:\n",
        "            return known\n",
        "    media_exts = {\"png\",\"jpg\",\"jpeg\",\"webp\",\"gif\",\"bmp\",\"tiff\",\"tif\",\n",
        "                  \"mp4\",\"avi\",\"mov\",\"mkv\",\"webm\",\"mp3\",\"wav\",\"flac\",\"ogg\"}\n",
        "    for field, val in inputs.items():\n",
        "        if isinstance(val, str) and Path(val).suffix.lower().lstrip('.') in media_exts:\n",
        "            return field\n",
        "    short = [f for f, v in inputs.items()\n",
        "             if isinstance(v, str) and len(v) < 256 and not v.startswith((\"http\", \"{\"))]\n",
        "    if short:\n",
        "        return short[0]\n",
        "    raise ValueError(f\"Can't detect input field on node '{node_id}'. Inputs: {list(inputs.keys())}\")\n",
        "\n",
        "def wait_for_comfyui(timeout=120):\n",
        "    print(\"â³ Waiting for ComfyUI...\", end=\"\", flush=True)\n",
        "    deadline = time.time() + timeout\n",
        "    while time.time() < deadline:\n",
        "        try:\n",
        "            if requests.get(f\"{COMFYUI_URL}/system_stats\", timeout=3).status_code == 200:\n",
        "                print(\" âœ… Ready!\")\n",
        "                return\n",
        "        except Exception:\n",
        "            pass\n",
        "        print(\".\", end=\"\", flush=True)\n",
        "        time.sleep(2)\n",
        "    raise TimeoutError(\"ComfyUI did not start in time.\")\n",
        "\n",
        "def queue_prompt(workflow):\n",
        "    client_id = str(uuid.uuid4())\n",
        "    r = requests.post(f\"{COMFYUI_URL}/prompt\",\n",
        "                      json={\"prompt\": workflow, \"client_id\": client_id}, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    if \"error\" in data:\n",
        "        raise RuntimeError(f\"Prompt error: {data['error']}\")\n",
        "    return data[\"prompt_id\"]\n",
        "\n",
        "def poll_until_done(prompt_id, timeout=600):\n",
        "    deadline = time.time() + timeout\n",
        "    while time.time() < deadline:\n",
        "        time.sleep(3)\n",
        "        try:\n",
        "            r = requests.get(f\"{COMFYUI_URL}/history/{prompt_id}\", timeout=10)\n",
        "            r.raise_for_status()\n",
        "            history = r.json()\n",
        "        except Exception:\n",
        "            continue\n",
        "        if prompt_id not in history:\n",
        "            continue\n",
        "        outputs = []\n",
        "        for _, node_out in history[prompt_id].get(\"outputs\", {}).items():\n",
        "            for _, items in node_out.items():\n",
        "                if isinstance(items, list):\n",
        "                    for item in items:\n",
        "                        if isinstance(item, dict) and \"filename\" in item:\n",
        "                            outputs.append(item)\n",
        "        return outputs\n",
        "    raise TimeoutError(f\"Prompt {prompt_id} timed out after {timeout}s\")\n",
        "\n",
        "def fetch_and_save_output(file_info, dest_dirs, stem):\n",
        "    params = {\"filename\": file_info[\"filename\"],\n",
        "              \"subfolder\": file_info.get(\"subfolder\", \"\"),\n",
        "              \"type\": file_info.get(\"type\", \"output\")}\n",
        "    r = requests.get(f\"{COMFYUI_URL}/view\", params=params, timeout=120)\n",
        "    r.raise_for_status()\n",
        "    ext  = Path(file_info[\"filename\"]).suffix\n",
        "    ts   = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    name = f\"{stem}_{ts}{ext}\"\n",
        "    saved = []\n",
        "    for dest in dest_dirs:\n",
        "        os.makedirs(dest, exist_ok=True)\n",
        "        out_path = os.path.join(dest, name)\n",
        "        with open(out_path, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "        saved.append(out_path)\n",
        "    return saved\n",
        "\n",
        "def copy_input_to_comfyui(src_path):\n",
        "    comfyui_input = \"/content/ComfyUI/input\"\n",
        "    os.makedirs(comfyui_input, exist_ok=True)\n",
        "    filename = Path(src_path).name\n",
        "    shutil.copy2(src_path, os.path.join(comfyui_input, filename))\n",
        "    return filename\n",
        "\n",
        "def process_file(filepath):\n",
        "    stem = Path(filepath).stem\n",
        "    print(f\"\\n{'â”€'*55}\")\n",
        "    print(f\"ğŸ“‚ {Path(filepath).name}  [{datetime.now().strftime('%H:%M:%S')}]\")\n",
        "    workflow = load_workflow()\n",
        "    field    = auto_detect_field(workflow, INPUT_NODE_ID)\n",
        "    filename = copy_input_to_comfyui(filepath)\n",
        "    workflow[INPUT_NODE_ID][\"inputs\"][field] = filename\n",
        "    print(f\"   Node [{INPUT_NODE_ID}].{field} â†’ '{filename}'\")\n",
        "    prompt_id = queue_prompt(workflow)\n",
        "    print(f\"   Queued: {prompt_id}\")\n",
        "    print(\"   â³ Running...\", end=\"\", flush=True)\n",
        "    output_files = poll_until_done(prompt_id)\n",
        "    print(f\" done â€” {len(output_files)} output(s)\")\n",
        "    dest_dirs = [OUTPUT_DIR] + ([EXTRA_DIR] if EXTRA_DIR else [])\n",
        "    for fi in output_files:\n",
        "        for p in fetch_and_save_output(fi, dest_dirs, stem):\n",
        "            print(f\"   ğŸ’¾ {p}\")\n",
        "    if not output_files:\n",
        "        print(\"   âš ï¸  No outputs â€” check workflow has a Save node.\")\n",
        "    dest_proc = os.path.join(PROCESSED_DIR, Path(filepath).name)\n",
        "    if os.path.exists(dest_proc):\n",
        "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        dest_proc = os.path.join(PROCESSED_DIR, f\"{stem}_{ts}{Path(filepath).suffix}\")\n",
        "    shutil.move(filepath, dest_proc)\n",
        "    print(f\"   ğŸ“¦ Moved to processed\")\n",
        "\n",
        "def run_watcher():\n",
        "    wait_for_comfyui()\n",
        "    try:\n",
        "        wf    = load_workflow()\n",
        "        field = auto_detect_field(wf, INPUT_NODE_ID)\n",
        "        cls   = wf[INPUT_NODE_ID].get(\"class_type\", \"unknown\")\n",
        "        print(f\"\\nâœ… Workflow: {WORKFLOW_PATH}\")\n",
        "        print(f\"   Node [{INPUT_NODE_ID}] {cls} â†’ field: '{field}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâš ï¸  Workflow check failed: {e}\")\n",
        "        return\n",
        "    print(f\"\\nğŸ‘€ Watching '{INPUT_FOLDER}' every {POLL_INTERVAL}s\")\n",
        "    print(\"   Drop files into the input folder to trigger the workflow.\\n\")\n",
        "    seen_errors = {}\n",
        "    while True:\n",
        "        try:\n",
        "            candidates = sorted(set(\n",
        "                f for ext in EXTENSIONS\n",
        "                for f in glob.glob(os.path.join(INPUT_FOLDER, f\"*.{ext}\")) +\n",
        "                          glob.glob(os.path.join(INPUT_FOLDER, f\"*.{ext.upper()}\"))\n",
        "            ))\n",
        "            for fp in candidates:\n",
        "                if seen_errors.get(fp, 0) >= 3:\n",
        "                    continue\n",
        "                try:\n",
        "                    process_file(fp)\n",
        "                    seen_errors.pop(fp, None)\n",
        "                except Exception as e:\n",
        "                    seen_errors[fp] = seen_errors.get(fp, 0) + 1\n",
        "                    print(f\"\\nâŒ Error ({seen_errors[fp]}/3) â€” {Path(fp).name}: {e}\")\n",
        "                    if seen_errors[fp] >= 3:\n",
        "                        print(f\"   â›” Giving up on {Path(fp).name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  Watcher error: {e}\")\n",
        "        time.sleep(POLL_INTERVAL)\n",
        "\n",
        "# â”€â”€ Launch modes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def start_window(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        if sock.connect_ex(('127.0.0.1', port)) == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "    from google.colab import output as co\n",
        "    print(\"\\nğŸŒ ComfyUI is ready!\")\n",
        "    co.serve_kernel_port_as_window(port)\n",
        "\n",
        "def start_iframe(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        if sock.connect_ex(('127.0.0.1', port)) == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "    from google.colab import output as co\n",
        "    print(\"\\nğŸŒ ComfyUI is ready!\")\n",
        "    co.serve_kernel_port_as_iframe(port, height=900)\n",
        "    co.serve_kernel_port_as_window(port)\n",
        "\n",
        "def start_cloudflare(port):\n",
        "    subprocess.run([\"wget\", \"-q\",\n",
        "        \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\"])\n",
        "    subprocess.run([\"dpkg\", \"-i\", \"cloudflared-linux-amd64.deb\"], capture_output=True)\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        if sock.connect_ex(('127.0.0.1', port)) == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "    print(\"\\nğŸŒ Launching Cloudflare tunnel...\")\n",
        "    p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", f\"http://127.0.0.1:{port}\"],\n",
        "                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    for line in p.stderr:\n",
        "        l = line.decode()\n",
        "        if \"trycloudflare.com\" in l:\n",
        "            print(\"ComfyUI URL:\", l[l.find(\"http\"):], end='')\n",
        "\n",
        "# â”€â”€ Print summary & start â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"=\" * 55)\n",
        "print(\"ğŸ—‚ï¸  ComfyUI Batch Workflow Runner\")\n",
        "print(\"=\" * 55)\n",
        "print(f\"  Mode       : {LAUNCH_MODE} | Batch: {BATCH_MODE}\")\n",
        "if BATCH_MODE:\n",
        "    print(f\"  Input      : {INPUT_FOLDER}\")\n",
        "    print(f\"  Output     : {OUTPUT_DIR}\")\n",
        "    print(f\"  Workflow   : {WORKFLOW_PATH}\")\n",
        "    print(f\"  Node ID    : {INPUT_NODE_ID}\")\n",
        "    print(f\"  Poll       : {POLL_INTERVAL}s\")\n",
        "    if EXTRA_DIR:\n",
        "        print(f\"  Extra out  : {EXTRA_DIR}\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "%cd /content/ComfyUI\n",
        "\n",
        "if LAUNCH_MODE == \"iframe\":\n",
        "    threading.Thread(target=start_iframe,     daemon=True, args=(8188,)).start()\n",
        "elif LAUNCH_MODE == \"cloudflare\":\n",
        "    threading.Thread(target=start_cloudflare, daemon=True, args=(8188,)).start()\n",
        "else:\n",
        "    threading.Thread(target=start_window,     daemon=True, args=(8188,)).start()\n",
        "\n",
        "if BATCH_MODE:\n",
        "    threading.Thread(target=run_watcher, daemon=True).start()\n",
        "\n",
        "print(\"\\nğŸš€ Starting ComfyUI...\\n\")\n",
        "!python main.py --highvram --cuda-malloc --use-sage-attention --fast --dont-print-server\n"
      ],
      "id": "I0zKPtIoVhjP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_sJ-PyTVhjQ"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“ Notes\n",
        "\n",
        "**Workflow format** â€” Export via ComfyUI â†’ Settings â†’ Dev Mode â†’ *Save (API Format)*. Uses numeric node IDs as top-level keys.\n",
        "\n",
        "**Input node ID** â€” open `workflow.json`, find your Load Image / Load Video node, its top-level key (e.g. `\"12\"`) is `INPUT_NODE_ID`. The input field is auto-detected and printed on startup.\n",
        "\n",
        "**Batch mode off** â€” set `BATCH_MODE = False` to just launch ComfyUI without the watcher. Useful when you want to use the UI manually.\n",
        "\n",
        "**Launch modes** â€” `window` opens a new tab, `iframe` embeds in the cell, `cloudflare` gives a public shareable URL.\n",
        "\n",
        "**Error handling** â€” files that fail 3 times are skipped permanently so the watcher never loops.\n",
        "\n",
        "**Live edits** â€” workflow JSON is re-read on every file so you can tweak it without restarting.\n",
        "\n",
        "---\n"
      ],
      "id": "D_sJ-PyTVhjQ"
    }
  ]
}