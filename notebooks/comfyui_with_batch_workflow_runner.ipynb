{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "# üé® Vanilla ComfyUI Colab\n",
        "\n",
        "A clean, minimal setup for running ComfyUI in Google Colab.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install-comfyui"
      },
      "source": [
        "## üì¶ Install ComfyUI & Dependencies\n",
        "\n",
        "This will install ComfyUI, all required dependencies, and ComfyUI Manager."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-F-LOeT4AN_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6ddc0d-33cb-4275-fc9e-731e712ab9f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Cloning ComfyUI repository...\n",
            "Cloning into '/content/ComfyUI'...\n",
            "remote: Enumerating objects: 31542, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 31542 (delta 19), reused 13 (delta 13), pack-reused 31512 (from 3)\u001b[K\n",
            "Receiving objects: 100% (31542/31542), 77.21 MiB | 12.91 MiB/s, done.\n",
            "Resolving deltas: 100% (21465/21465), done.\n",
            "‚úÖ ComfyUI cloned successfully\n",
            "\n",
            "/content/ComfyUI\n",
            "üîÑ Updating ComfyUI...\n",
            "Already up to date.\n",
            "‚úÖ ComfyUI updated\n",
            "\n",
            "üì¶ Installing dependencies...\n",
            "\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚ö° Installing PyTorch with CUDA 12.1...\n",
            "üìö Installing core dependencies...\n",
            "ü§ó Installing transformers and huggingface-hub...\n",
            "üöÄ Installing optional packages...\n",
            "‚úÖ All dependencies installed successfully!\n",
            "\n",
            "üì• Installing ComfyUI Manager...\n",
            "Cloning into '/content/ComfyUI/custom_nodes/ComfyUI-Manager'...\n",
            "remote: Enumerating objects: 28262, done.\u001b[K\n",
            "remote: Counting objects: 100% (756/756), done.\u001b[K\n",
            "remote: Compressing objects: 100% (348/348), done.\u001b[K\n",
            "remote: Total 28262 (delta 608), reused 422 (delta 408), pack-reused 27506 (from 4)\u001b[K\n",
            "Receiving objects: 100% (28262/28262), 127.25 MiB | 32.63 MiB/s, done.\n",
            "Resolving deltas: 100% (20947/20947), done.\n",
            "‚úÖ ComfyUI Manager installed\n",
            "\n",
            "üìã Installed versions:\n",
            "\n",
            "  ‚úÖ torch: 2.9.0+cu126\n",
            "  ‚úÖ transformers: 4.56.2\n",
            "  ‚úÖ huggingface-hub: 0.36.1\n",
            "  ‚úÖ tokenizers: 0.22.2\n",
            "  ‚úÖ safetensors: 0.7.0\n",
            "\n",
            "==================================================\n",
            "üéâ Installation complete!\n",
            "==================================================\n",
            "\n",
            "‚úÖ You can now run the Launch cell below!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "WORKSPACE = \"/content/ComfyUI\"\n",
        "\n",
        "# ========================================\n",
        "# 1. Clone ComfyUI\n",
        "# ========================================\n",
        "if not os.path.exists(WORKSPACE):\n",
        "    print(\"üì• Cloning ComfyUI repository...\")\n",
        "    !git clone https://github.com/comfyanonymous/ComfyUI {WORKSPACE}\n",
        "    print(\"‚úÖ ComfyUI cloned successfully\\n\")\n",
        "else:\n",
        "    print(\"‚úÖ ComfyUI directory already exists\\n\")\n",
        "\n",
        "# Change to ComfyUI directory\n",
        "%cd {WORKSPACE}\n",
        "\n",
        "# Update ComfyUI\n",
        "print(\"üîÑ Updating ComfyUI...\")\n",
        "!git pull\n",
        "print(\"‚úÖ ComfyUI updated\\n\")\n",
        "\n",
        "# ========================================\n",
        "# 2. Install Dependencies\n",
        "# ========================================\n",
        "print(\"üì¶ Installing dependencies...\\n\")\n",
        "\n",
        "# Upgrade pip\n",
        "!pip install --upgrade pip -q\n",
        "\n",
        "# Install PyTorch with CUDA support\n",
        "print(\"‚ö° Installing PyTorch with CUDA 12.1...\")\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 -q\n",
        "\n",
        "# Install core dependencies\n",
        "print(\"üìö Installing core dependencies...\")\n",
        "!pip install -q \\\n",
        "    accelerate \\\n",
        "    einops \\\n",
        "    \"safetensors>=0.4.2\" \\\n",
        "    aiohttp \\\n",
        "    pyyaml \\\n",
        "    Pillow \\\n",
        "    scipy \\\n",
        "    tqdm \\\n",
        "    psutil \\\n",
        "    \"tokenizers>=0.13.3\" \\\n",
        "    sentencepiece \\\n",
        "    soundfile \\\n",
        "    \"kornia>=0.7.1\" \\\n",
        "    spandrel \\\n",
        "    torchsde \\\n",
        "    comfy_aimdo \\\n",
        "    av \\\n",
        "    comfy-kitchen \\\n",
        "    comfyui-workflow-templates \\\n",
        "    comfyui-embedded-docs\n",
        "\n",
        "# Install transformers and huggingface-hub with compatible versions\n",
        "print(\"ü§ó Installing transformers and huggingface-hub...\")\n",
        "!pip install -q \\\n",
        "    \"transformers>=4.45.0,<4.57.0\" \\\n",
        "    \"huggingface-hub>=0.23.0,<1.0\"\n",
        "\n",
        "# Install optional speedup packages\n",
        "print(\"üöÄ Installing optional packages...\")\n",
        "!pip install -q hf_transfer\n",
        "\n",
        "print(\"‚úÖ All dependencies installed successfully!\\n\")\n",
        "\n",
        "# ========================================\n",
        "# 3. Install ComfyUI Manager\n",
        "# ========================================\n",
        "manager_path = f\"{WORKSPACE}/custom_nodes/ComfyUI-Manager\"\n",
        "\n",
        "if not os.path.exists(manager_path):\n",
        "    print(\"üì• Installing ComfyUI Manager...\")\n",
        "    !git clone https://github.com/ltdrdata/ComfyUI-Manager {manager_path}\n",
        "    print(\"‚úÖ ComfyUI Manager installed\\n\")\n",
        "else:\n",
        "    print(\"üîÑ Updating ComfyUI Manager...\")\n",
        "    !cd {manager_path} && git pull\n",
        "    print(\"‚úÖ ComfyUI Manager updated\\n\")\n",
        "\n",
        "# ========================================\n",
        "# 4. Verify Installation\n",
        "# ========================================\n",
        "import importlib.metadata as metadata\n",
        "\n",
        "print(\"üìã Installed versions:\\n\")\n",
        "\n",
        "packages = [\n",
        "    \"torch\",\n",
        "    \"transformers\",\n",
        "    \"huggingface-hub\",\n",
        "    \"tokenizers\",\n",
        "    \"safetensors\"\n",
        "]\n",
        "\n",
        "for pkg in packages:\n",
        "    try:\n",
        "        version = metadata.version(pkg)\n",
        "        print(f\"  ‚úÖ {pkg}: {version}\")\n",
        "    except:\n",
        "        print(f\"  ‚ùå {pkg}: not found\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üéâ Installation complete!\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\n‚úÖ You can now run the Launch cell below!\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# üì©Install Custom Models and Nodes"
      ],
      "metadata": {
        "id": "EwRf3DiJK3vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Install Models & Custom Nodes\n",
        "# ========================================\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"üì¶ Installing Models & Custom Nodes\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "MODELS_DIR = \"/content/ComfyUI/models\"\n",
        "CUSTOM_NODES_DIR = \"/content/ComfyUI/custom_nodes\"\n",
        "\n",
        "# Enable fast HuggingFace downloads\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "\n",
        "# ========================================\n",
        "# ‚öôÔ∏è CONFIGURATION - Just add links here\n",
        "# ========================================\n",
        "\n",
        "# Custom Nodes - GitHub repository URLs\n",
        "CUSTOM_NODES = [\n",
        "    \"https://github.com/nagadomi/lbpcascade_animeface/blob/master/lbpcascade_animeface.xml\",\n",
        "    # Add more links here...\n",
        "]\n",
        "\n",
        "# Models - HuggingFace URLs or direct download links\n",
        "MODELS = [\n",
        "    #\"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/realisticVisionV51_v51VAE.safetensors\",\n",
        "    # Add more links here...\n",
        "]\n",
        "\n",
        "# ========================================\n",
        "# Auto-detect and install\n",
        "# ========================================\n",
        "\n",
        "# Install Custom Nodes\n",
        "if CUSTOM_NODES:\n",
        "    print(\"üîß Installing Custom Nodes...\\n\")\n",
        "    for repo_url in CUSTOM_NODES:\n",
        "        node_name = repo_url.split('/')[-1].replace('.git', '')\n",
        "        node_path = f\"{CUSTOM_NODES_DIR}/{node_name}\"\n",
        "\n",
        "        if not os.path.exists(node_path):\n",
        "            print(f\"üì• {node_name}...\")\n",
        "            !git clone -q {repo_url} {node_path}\n",
        "            print(f\"‚úÖ {node_name} installed\")\n",
        "        else:\n",
        "            print(f\"‚è≠Ô∏è  {node_name} (already exists)\")\n",
        "\n",
        "    print(\"\\nüìö Installing dependencies...\")\n",
        "    !find {CUSTOM_NODES_DIR} -name \"requirements.txt\" -exec pip install -q -r {} \\;\n",
        "    print(\"‚úÖ Dependencies installed\\n\")\n",
        "\n",
        "# Download Models\n",
        "if MODELS:\n",
        "    from huggingface_hub import hf_hub_download\n",
        "    print(\"üé® Downloading Models (with fast HF transfer)...\\n\")\n",
        "\n",
        "    for url in MODELS:\n",
        "        filename = url.split('/')[-1].split('?')[0]\n",
        "\n",
        "        # Auto-detect folder based on file extension/name\n",
        "        if \"upscale\" in filename.lower() or filename.endswith('.pth'):\n",
        "            model_dir = f\"{MODELS_DIR}/upscale_models\"\n",
        "        elif \"controlnet\" in filename.lower():\n",
        "            model_dir = f\"{MODELS_DIR}/controlnet\"\n",
        "        elif \"yolo\" in filename.lower() or \"face\" in filename.lower():\n",
        "            model_dir = f\"{MODELS_DIR}/ultralytics/bbox\"\n",
        "        else:\n",
        "            model_dir = f\"{MODELS_DIR}/checkpoints\"\n",
        "\n",
        "        os.makedirs(model_dir, exist_ok=True)\n",
        "        filepath = f\"{model_dir}/{filename}\"\n",
        "\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"üì• {filename} ‚Üí {model_dir.split('/')[-1]}/\")\n",
        "\n",
        "            if \"huggingface.co\" in url:\n",
        "                parts = url.split(\"huggingface.co/\")[1].split(\"/\")\n",
        "                repo_id = f\"{parts[0]}/{parts[1]}\"\n",
        "                file_path = \"/\".join(parts[4:])\n",
        "\n",
        "                try:\n",
        "                    hf_hub_download(\n",
        "                        repo_id=repo_id,\n",
        "                        filename=file_path,\n",
        "                        local_dir=model_dir,\n",
        "                        local_dir_use_symlinks=False\n",
        "                    )\n",
        "                    print(f\"‚úÖ Downloaded\\n\")\n",
        "                except:\n",
        "                    !wget -q --show-progress -c \"{url}\" -O {filepath}\n",
        "            else:\n",
        "                !wget -q --show-progress -c \"{url}\" -O {filepath}\n",
        "        else:\n",
        "            print(f\"‚è≠Ô∏è  {filename} (already exists)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"‚úÖ Installation Complete!\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrsuMAQqK2gb",
        "outputId": "077a3fb6-40a0-4b09-bdae-a315229b2881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "üì¶ Installing Models & Custom Nodes\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "‚úÖ Installation Complete!\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "batch-runner-header"
      },
      "source": [
        "---\n",
        "\n",
        "# ‚öôÔ∏è Batch Workflow Runner\n",
        "\n",
        "Watches an **input** folder, runs any file through a ComfyUI workflow automatically, saves outputs, and moves processed files.\n",
        "\n",
        "**Folder structure** (all created automatically):\n",
        "```\n",
        "MAIN_FOLDER/\n",
        "  ‚îú‚îÄ‚îÄ input/        ‚Üê drop files here\n",
        "  ‚îú‚îÄ‚îÄ processed/    ‚Üê files moved here after running\n",
        "  ‚îú‚îÄ‚îÄ output/       ‚Üê ComfyUI outputs saved here\n",
        "  ‚îî‚îÄ‚îÄ workflow.json ‚Üê your exported ComfyUI workflow (API format)\n",
        "```\n",
        "\n",
        "> **How to export workflow in API format:** In ComfyUI ‚Üí Settings ‚Üí Enable Dev Mode ‚Üí \"Save (API Format)\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batch-runner-cell"
      },
      "outputs": [],
      "source": [
        "import os, time, json, shutil, threading, socket, glob, requests, uuid\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë                     ‚öôÔ∏è  CONFIGURATION                           ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "# @title ‚öôÔ∏è Configuration\n",
        "# @markdown ---\n",
        "# @markdown ### üìÅ Folder Settings\n",
        "# @markdown **Main folder** ‚Äì all subfolders live here (input / processed / output).\n",
        "# @markdown Can be a Google Drive path or any Colab path.\n",
        "MAIN_FOLDER = \"/content/drive/MyDrive/ComfyUI_Batch\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **Extra output path** ‚Äì optional second save location. Leave blank to skip.\n",
        "EXTRA_OUTPUT_PATH = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### üîÑ Workflow Settings\n",
        "# @markdown Filename of your workflow JSON inside MAIN_FOLDER.\n",
        "WORKFLOW_FILENAME = \"workflow.json\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### üéØ Input Node Config\n",
        "# @markdown The node ID where the input file is injected.\n",
        "# @markdown Find it by opening your workflow JSON ‚Äî the top-level numeric key of your\n",
        "# @markdown Load Image / Load Video node (e.g. \"12\"). The input field is auto-detected.\n",
        "INPUT_NODE_ID = \"1\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### ‚è±Ô∏è Watcher Settings\n",
        "# @markdown How often (seconds) to check the input folder for new files.\n",
        "POLL_INTERVAL = 10  # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown Supported file extensions to watch for.\n",
        "SUPPORTED_EXTENSIONS = \"png,jpg,jpeg,webp,mp4,gif,bmp,tiff\"  # @param {type:\"string\"}\n",
        "\n",
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë                   üîß  SETUP & HELPERS                           ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "COMFYUI_URL   = \"http://127.0.0.1:8188\"\n",
        "INPUT_FOLDER  = os.path.join(MAIN_FOLDER, \"input\")\n",
        "PROCESSED_DIR = os.path.join(MAIN_FOLDER, \"processed\")\n",
        "OUTPUT_DIR    = os.path.join(MAIN_FOLDER, \"output\")\n",
        "WORKFLOW_PATH = os.path.join(MAIN_FOLDER, WORKFLOW_FILENAME)\n",
        "\n",
        "EXTRA_OUTPUT_PATH = EXTRA_OUTPUT_PATH.strip()\n",
        "EXTRA_DIR = EXTRA_OUTPUT_PATH if EXTRA_OUTPUT_PATH else None\n",
        "\n",
        "EXTENSIONS = {e.strip().lower().lstrip('.') for e in SUPPORTED_EXTENSIONS.split(',') if e.strip()}\n",
        "\n",
        "# Known field names that carry a file/image path, in priority order\n",
        "_FILE_FIELDS = [\n",
        "    \"image\", \"video\", \"audio\", \"file\", \"mask\",\n",
        "    \"image_path\", \"video_path\", \"file_path\",\n",
        "    \"input\", \"source\", \"path\",\n",
        "]\n",
        "\n",
        "for d in [INPUT_FOLDER, PROCESSED_DIR, OUTPUT_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "if EXTRA_DIR:\n",
        "    os.makedirs(EXTRA_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def load_workflow() -> dict:\n",
        "    \"\"\"Load the workflow JSON from disk (re-read every run so edits take effect).\"\"\"\n",
        "    if not os.path.exists(WORKFLOW_PATH):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Workflow not found: {WORKFLOW_PATH}\\n\"\n",
        "            \"Export your workflow in API format from ComfyUI and save it there.\"\n",
        "        )\n",
        "    with open(WORKFLOW_PATH, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def auto_detect_field(workflow: dict, node_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Auto-detect which input field of a node holds the file path.\n",
        "    Strategy:\n",
        "      1. Check against known field name list (priority order).\n",
        "      2. Fall back to any field whose current value is a string ending with\n",
        "         a known image/video extension.\n",
        "      3. Fall back to any string field that isn't a URL or long prompt text.\n",
        "    Raises ValueError with a helpful message if nothing is found.\n",
        "    \"\"\"\n",
        "    if node_id not in workflow:\n",
        "        raise KeyError(\n",
        "            f\"Node '{node_id}' not found in workflow.\\n\"\n",
        "            f\"Available node IDs: {list(workflow.keys())}\"\n",
        "        )\n",
        "\n",
        "    inputs = workflow[node_id].get(\"inputs\", {})\n",
        "\n",
        "    # 1. Priority match against known field names\n",
        "    for known in _FILE_FIELDS:\n",
        "        if known in inputs:\n",
        "            return known\n",
        "\n",
        "    # 2. Any field whose value looks like a filename with a media extension\n",
        "    media_exts = {\n",
        "        \"png\",\"jpg\",\"jpeg\",\"webp\",\"gif\",\"bmp\",\"tiff\",\"tif\",\n",
        "        \"mp4\",\"avi\",\"mov\",\"mkv\",\"webm\",\n",
        "        \"mp3\",\"wav\",\"flac\",\"ogg\",\n",
        "    }\n",
        "    for field, val in inputs.items():\n",
        "        if isinstance(val, str) and Path(val).suffix.lower().lstrip('.') in media_exts:\n",
        "            return field\n",
        "\n",
        "    # 3. Any plain string field that isn't suspiciously long (i.e. not a prompt)\n",
        "    short_strings = [\n",
        "        field for field, val in inputs.items()\n",
        "        if isinstance(val, str) and len(val) < 256 and not val.startswith((\"http\", \"{\"))\n",
        "    ]\n",
        "    if short_strings:\n",
        "        return short_strings[0]\n",
        "\n",
        "    raise ValueError(\n",
        "        f\"Could not auto-detect an input file field on node '{node_id}'.\\n\"\n",
        "        f\"Node inputs: {list(inputs.keys())}\\n\"\n",
        "        f\"Rename one of those fields to 'image' or 'video', or check your node ID.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def wait_for_comfyui(timeout: int = 120):\n",
        "    \"\"\"Block until ComfyUI HTTP server responds.\"\"\"\n",
        "    print(\"‚è≥ Waiting for ComfyUI to start...\", end=\"\", flush=True)\n",
        "    deadline = time.time() + timeout\n",
        "    while time.time() < deadline:\n",
        "        try:\n",
        "            r = requests.get(f\"{COMFYUI_URL}/system_stats\", timeout=3)\n",
        "            if r.status_code == 200:\n",
        "                print(\" ‚úÖ Ready!\")\n",
        "                return\n",
        "        except Exception:\n",
        "            pass\n",
        "        print(\".\", end=\"\", flush=True)\n",
        "        time.sleep(2)\n",
        "    raise TimeoutError(\"ComfyUI did not start within the timeout window.\")\n",
        "\n",
        "\n",
        "def queue_prompt(workflow: dict) -> str:\n",
        "    \"\"\"Submit workflow to ComfyUI and return the prompt_id.\"\"\"\n",
        "    client_id = str(uuid.uuid4())\n",
        "    payload = {\"prompt\": workflow, \"client_id\": client_id}\n",
        "    r = requests.post(f\"{COMFYUI_URL}/prompt\", json=payload, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    if \"error\" in data:\n",
        "        raise RuntimeError(f\"ComfyUI prompt error: {data['error']}\")\n",
        "    return data[\"prompt_id\"]\n",
        "\n",
        "\n",
        "def poll_until_done(prompt_id: str, timeout: int = 600) -> list:\n",
        "    \"\"\"Poll /history until the prompt finishes; return list of output file info dicts.\"\"\"\n",
        "    deadline = time.time() + timeout\n",
        "    while time.time() < deadline:\n",
        "        time.sleep(3)\n",
        "        try:\n",
        "            r = requests.get(f\"{COMFYUI_URL}/history/{prompt_id}\", timeout=10)\n",
        "            r.raise_for_status()\n",
        "            history = r.json()\n",
        "        except Exception:\n",
        "            continue\n",
        "        if prompt_id not in history:\n",
        "            continue\n",
        "        entry = history[prompt_id]\n",
        "        outputs = []\n",
        "        for node_id, node_out in entry.get(\"outputs\", {}).items():\n",
        "            for key, items in node_out.items():\n",
        "                if isinstance(items, list):\n",
        "                    for item in items:\n",
        "                        if isinstance(item, dict) and \"filename\" in item:\n",
        "                            outputs.append(item)\n",
        "        return outputs\n",
        "    raise TimeoutError(f\"Prompt {prompt_id} did not finish within {timeout}s\")\n",
        "\n",
        "\n",
        "def fetch_and_save_output(file_info: dict, dest_dirs: list, stem: str) -> list:\n",
        "    \"\"\"Download a single output file from ComfyUI and save to all dest_dirs.\"\"\"\n",
        "    filename  = file_info[\"filename\"]\n",
        "    subfolder = file_info.get(\"subfolder\", \"\")\n",
        "    ftype     = file_info.get(\"type\", \"output\")\n",
        "\n",
        "    params = {\"filename\": filename, \"subfolder\": subfolder, \"type\": ftype}\n",
        "    r = requests.get(f\"{COMFYUI_URL}/view\", params=params, timeout=120)\n",
        "    r.raise_for_status()\n",
        "\n",
        "    ext = Path(filename).suffix\n",
        "    ts  = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    save_name = f\"{stem}_{ts}{ext}\"\n",
        "\n",
        "    saved = []\n",
        "    for dest in dest_dirs:\n",
        "        os.makedirs(dest, exist_ok=True)\n",
        "        out_path = os.path.join(dest, save_name)\n",
        "        with open(out_path, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "        saved.append(out_path)\n",
        "    return saved\n",
        "\n",
        "\n",
        "def copy_input_to_comfyui(src_path: str) -> str:\n",
        "    \"\"\"Copy the input file into ComfyUI's own input folder; return the filename.\"\"\"\n",
        "    comfyui_input = \"/content/ComfyUI/input\"\n",
        "    os.makedirs(comfyui_input, exist_ok=True)\n",
        "    filename = Path(src_path).name\n",
        "    shutil.copy2(src_path, os.path.join(comfyui_input, filename))\n",
        "    return filename\n",
        "\n",
        "\n",
        "def process_file(filepath: str):\n",
        "    \"\"\"Run one input file through the workflow end-to-end.\"\"\"\n",
        "    stem = Path(filepath).stem\n",
        "    print(f\"\\n{'‚îÄ'*55}\")\n",
        "    print(f\"üìÇ Processing : {Path(filepath).name}\")\n",
        "    print(f\"   Started at : {datetime.now().strftime('%H:%M:%S')}\")\n",
        "\n",
        "    # 1. Load workflow fresh (picks up any edits without restarting)\n",
        "    workflow = load_workflow()\n",
        "\n",
        "    # 2. Auto-detect the file input field on the configured node\n",
        "    detected_field = auto_detect_field(workflow, INPUT_NODE_ID)\n",
        "\n",
        "    # 3. Copy file into ComfyUI input dir and inject filename into the node\n",
        "    input_filename = copy_input_to_comfyui(filepath)\n",
        "    workflow[INPUT_NODE_ID][\"inputs\"][detected_field] = input_filename\n",
        "    print(f\"   Node [{INPUT_NODE_ID}].{detected_field} ‚Üí '{input_filename}'  (auto-detected)\")\n",
        "\n",
        "    # 4. Queue\n",
        "    prompt_id = queue_prompt(workflow)\n",
        "    print(f\"   Prompt ID   : {prompt_id}\")\n",
        "\n",
        "    # 5. Wait for completion\n",
        "    print(\"   ‚è≥ Running workflow...\", end=\"\", flush=True)\n",
        "    output_files = poll_until_done(prompt_id)\n",
        "    print(f\" done! ({len(output_files)} output(s))\")\n",
        "\n",
        "    # 6. Save all outputs\n",
        "    dest_dirs = [OUTPUT_DIR]\n",
        "    if EXTRA_DIR:\n",
        "        dest_dirs.append(EXTRA_DIR)\n",
        "\n",
        "    saved_paths = []\n",
        "    for file_info in output_files:\n",
        "        paths = fetch_and_save_output(file_info, dest_dirs, stem)\n",
        "        saved_paths.extend(paths)\n",
        "        for p in paths:\n",
        "            print(f\"   üíæ Saved     : {p}\")\n",
        "\n",
        "    if not saved_paths:\n",
        "        print(\"   ‚ö†Ô∏è  No downloadable outputs (check workflow has a SaveImage / Save node).\")\n",
        "\n",
        "    # 7. Move input to processed\n",
        "    dest_processed = os.path.join(PROCESSED_DIR, Path(filepath).name)\n",
        "    if os.path.exists(dest_processed):\n",
        "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        dest_processed = os.path.join(PROCESSED_DIR, f\"{stem}_{ts}{Path(filepath).suffix}\")\n",
        "    shutil.move(filepath, dest_processed)\n",
        "    print(f\"   üì¶ Moved to  : {dest_processed}\")\n",
        "\n",
        "\n",
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë                 üöÄ  LAUNCH COMFYUI + WATCHER                    ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "def run_watcher():\n",
        "    \"\"\"Background thread: poll input folder and process new files.\"\"\"\n",
        "    wait_for_comfyui()\n",
        "\n",
        "    # Validate node + field detection once on startup with a dry-run\n",
        "    try:\n",
        "        wf = load_workflow()\n",
        "        field = auto_detect_field(wf, INPUT_NODE_ID)\n",
        "        node_class = wf[INPUT_NODE_ID].get(\"class_type\", \"unknown\")\n",
        "        print(f\"\\n‚úÖ Workflow loaded  : {WORKFLOW_PATH}\")\n",
        "        print(f\"   Input node       : [{INPUT_NODE_ID}] {node_class}\")\n",
        "        print(f\"   Auto-detected field: '{field}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ö†Ô∏è  Workflow pre-check failed: {e}\")\n",
        "        print(\"   Fix the issue above and restart the cell.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüëÄ Watching '{INPUT_FOLDER}' every {POLL_INTERVAL}s...\")\n",
        "    print(\"   Drop files into the input folder to trigger the workflow.\")\n",
        "    print(\"   Press Ctrl+C (or stop the cell) to quit.\\n\")\n",
        "\n",
        "    seen_errors = {}  # filepath ‚Üí error count\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            candidates = []\n",
        "            for ext in EXTENSIONS:\n",
        "                candidates.extend(glob.glob(os.path.join(INPUT_FOLDER, f\"*.{ext}\")))\n",
        "                candidates.extend(glob.glob(os.path.join(INPUT_FOLDER, f\"*.{ext.upper()}\")))\n",
        "            candidates = sorted(set(candidates))\n",
        "\n",
        "            if not candidates:\n",
        "                time.sleep(POLL_INTERVAL)\n",
        "                continue\n",
        "\n",
        "            for fp in candidates:\n",
        "                if seen_errors.get(fp, 0) >= 3:\n",
        "                    continue\n",
        "                try:\n",
        "                    process_file(fp)\n",
        "                    seen_errors.pop(fp, None)\n",
        "                except Exception as e:\n",
        "                    seen_errors[fp] = seen_errors.get(fp, 0) + 1\n",
        "                    count = seen_errors[fp]\n",
        "                    print(f\"\\n‚ùå Error ({count}/3) ‚Äî {Path(fp).name}: {e}\")\n",
        "                    if count >= 3:\n",
        "                        print(f\"   ‚õî Giving up on {Path(fp).name}.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Watcher loop error: {e}\")\n",
        "\n",
        "        time.sleep(POLL_INTERVAL)\n",
        "\n",
        "\n",
        "def iframe_thread(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        if sock.connect_ex(('127.0.0.1', port)) == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "    from google.colab import output as colab_output\n",
        "    print(\"\\nüåê ComfyUI is ready! Opening in iframe below...\")\n",
        "    print(\"üí° Tip: Click the link to open in a new window\\n\")\n",
        "    colab_output.serve_kernel_port_as_iframe(port, height=900)\n",
        "    colab_output.serve_kernel_port_as_window(port)\n",
        "\n",
        "\n",
        "# Print startup summary\n",
        "print(\"=\"*60)\n",
        "print(\"üóÇÔ∏è  ComfyUI Batch Workflow Runner\")\n",
        "print(\"=\"*60)\n",
        "print(f\"  Main folder   : {MAIN_FOLDER}\")\n",
        "print(f\"  Input         : {INPUT_FOLDER}\")\n",
        "print(f\"  Processed     : {PROCESSED_DIR}\")\n",
        "print(f\"  Output        : {OUTPUT_DIR}\")\n",
        "if EXTRA_DIR:\n",
        "    print(f\"  Extra output  : {EXTRA_DIR}\")\n",
        "print(f\"  Workflow      : {WORKFLOW_PATH}\")\n",
        "print(f\"  Input node ID : {INPUT_NODE_ID}  (field auto-detected at runtime)\")\n",
        "print(f\"  Poll interval : {POLL_INTERVAL}s\")\n",
        "print(f\"  Extensions    : {', '.join(sorted(EXTENSIONS))}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "%cd /content/ComfyUI\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "threading.Thread(target=run_watcher, daemon=True).start()\n",
        "\n",
        "print(\"\\nüöÄ Starting ComfyUI + Batch Watcher...\")\n",
        "print(\"‚è≥ Please wait for the interface to load below...\\n\")\n",
        "\n",
        "!python main.py --dont-print-server\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "notes"
      },
      "source": [
        "---\n",
        "\n",
        "## üìù Notes\n",
        "\n",
        "- **Workflow format**: Export using ComfyUI ‚Üí Settings ‚Üí Dev Mode ‚Üí *Save (API Format)*. The API format uses numeric node IDs as top-level keys.\n",
        "- **Input node ID**: Open your `workflow.json` and find the node that loads images/files (e.g. `LoadImage`, `VHS_LoadVideo`). Its top-level key (e.g. `\"12\"`) is the `INPUT_NODE_ID`.\n",
        "- **Field auto-detection**: The runner inspects the node's inputs and picks the first field that looks like a file path ‚Äî checking against known names (`image`, `video`, `audio`, `file`, ‚Ä¶) then by value type. The detected field is printed at startup so you can verify it.\n",
        "- **Output capture**: All nodes that produce files (SaveImage, VHS_VideoCombine, etc.) are captured automatically.\n",
        "- **Extra output**: Set `EXTRA_OUTPUT_PATH` to copy outputs to a second destination (e.g. another Drive folder).\n",
        "- **Error handling**: Files that fail 3 times are permanently skipped so the watcher doesn't loop forever.\n",
        "- **Live edits**: The workflow JSON is re-read on every file, so you can tweak it without restarting.\n",
        "\n",
        "---\n",
        "\n",
        "**Enjoy using ComfyUI Batch Runner! üé®**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}